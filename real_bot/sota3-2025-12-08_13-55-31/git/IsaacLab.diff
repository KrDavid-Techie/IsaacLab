--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   command.md
	modified:   real_bot/deploy_unitree.py
	deleted:    real_bot/sota_2025-11-06_11-43-35/events.out.tfevents.1762397031.DESKTOP-F5CN0L7.49960.0
	deleted:    real_bot/sota_2025-11-06_11-43-35/exported/policy.onnx
	deleted:    real_bot/sota_2025-11-06_11-43-35/exported/policy.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/git/IsaacLab.diff
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_0.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_100.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_150.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_200.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_250.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_300.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_350.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_400.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_450.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_50.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_500.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_550.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_600.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_650.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_700.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_750.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_800.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_850.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_900.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_950.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/model_999.pt
	deleted:    real_bot/sota_2025-11-06_11-43-35/params/agent.yaml
	deleted:    real_bot/sota_2025-11-06_11-43-35/params/env.yaml
	modified:   scripts/reinforcement_learning/rsl_rl/play.py
	modified:   source/isaaclab/isaaclab/envs/mdp/observations.py
	modified:   source/isaaclab/isaaclab/terrains/config/rough.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/agents/rsl_rl_ppo_cfg.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/rough_env_cfg_pdgain_fix.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/stair_env_cfg.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg_default.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	real_bot/sota-rough-2025-12-03_14-11-02/
	real_bot/sota-rough_2025-11-06_11-43-35/
	real_bot/sota-stair-2025-12-03_18-06-16/
	real_bot/test_policy.py
	real_bot/unitree_ros2/
	real_bot/unitree_sdk2/
	scripts/reinforcement_learning/gram_init/
	source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/stair_env_cfg_legged-loco.py

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/command.md b/command.md
index 930a74792d..edf8b1cfa5 100644
--- a/command.md
+++ b/command.md
@@ -12,112 +12,123 @@ isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task
 isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Flat-Unitree-Go2-v0 --num_envs 4096 --max_iterations 4000 --load_run "2025-11-14_09-41-57"
 # 기반학습
 ```
-
+---
+---
+---
+---
+---
 ### Rough
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 20 --max_iterations 100
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 1 --max_iterations 100
 # Visualized 
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 1000
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 1500
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 500 --resume --load_run "2025-11-06_11-43-35" 
-# 추가 학습
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 500 --resume --load_run "2025-11-24_19-17-49" 
+# 기반 학습
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 1000 --load_run "2025-11-20_08-15-24" 
-# 기반학습
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Rough-Unitree-Go2-v0 --num_envs 4096 --max_iterations 1000 --load_run "2025-12-03_14-11-02"
+# 추가 학습
 ```
+---
+---
+---
+---
+---
+### Stair
 
+```bash
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --headless --task Isaac-Velocity-Stair-Unitree-Go2-v0 --num_envs 4096 --max_iterations 1000
+```
+---
+---
+---
+---
+---
 ---------------
-
+---
+---
+---
+---
+---
 ## Play
 ### Flat
 ```bash
 isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Flat-Unitree-Go2-v0  --num_envs 10 --checkpoint checkpoint_path --log_joints --log_commands --log_interval 20
 ```
-
+---
+---
+---
+---
+---
 ### Rough
 ```bash
 isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 20 --checkpoint checkpoint_path 
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-11-06_11-43-35\model_999.pt #False
-```
-
-```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-11-06_11-43-35\model_999.pt --log_joints  --log_interval 40 #False
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 20 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\sota_2025-11-06_11-43-35\model_999.pt
+#False
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-11-17_17-32-35\model_1099.pt #False
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 20 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\sota2-2025-12-03_14-11-02\model_1499.pt --video --video_length 800
+#False
 ```
 
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-11-17_17-32-35\model_1099.pt --log_joints --log_commands --log_interval 20 #False
-```
-
-
----
----
----
----
----
-
-# SKRL
-## Train
-```bash
-isaaclab.bat -p scripts/reinforcement_learning/skrl/train.py --task Isaac-Velocity-Flat-Unitree-Go2-v0 --num_envs 4096 --max_iterations 500 --headless
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 20 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-12-04_11-48-06\model_999.pt
+#False
 ```
 
----------------
-
-## Play
 ```bash
-isaaclab.bat -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Velocity-Flat-Unitree-Go2-v0 --num_envs 8 --checkpoint C:\Users\User\github\IsaacLab\logs\skrl\unitree_go2_flat\2025-11-03_16-20-44_ppo_torch\checkpoints\best_agent.pt --video --video_length 200
-
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-Unitree-Go2-v0  --num_envs 20 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-12-04_18-29-47\model_4999.pt
+#False
 ```
 ---
 ---
 ---
 ---
 ---
-
-# Unitree_rl_lab
-## Train
+### Stair
 ```bash
-python scripts/rsl_rl/train.py --headless --max_iterations 20000 --num_envs 4096 --task Unitree-Go2-Velocity
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Stair-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_stair\2025-12-03_18-06-16\model_4999.pt
+#False
 ```
-
----------------
-
-## Play
 ```bash
-python scripts/rsl_rl/play.py --task Unitree-Go2-Velocity --num_envs 1 --checkpoint [] --video --video_length 800 --log_joints --log_commands
+isaaclab.bat -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Stair-Unitree-Go2-v0  --num_envs 10 --checkpoint C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_stair\2025-12-04_10-18-28\model_999.pt
+#False
 ```
-
 ---
 ---
 ---
 ---
 ---
-
 # Note 
 ```bash
-C:\Users\User\github\IsaacLab\source\isaaclab\isaaclab\envs\mdp\observations.py
-C:\Users\User\github\IsaacLab\source\isaaclab\isaaclab\managers\manager_term_cfg.py
-C:\Users\User\github\IsaacLab\source\isaaclab_tasks\isaaclab_tasks\manager_based\locomotion\velocity\velocity_env_cfg.py
-```
-```bash
-C:\Users\User\github\unitree_rl_lab\source\unitree_rl_lab\unitree_rl_lab\tasks\locomotion\robots\go2\velocity_env_cfg.py
-```
-```bash
 isaaclab.bat -p -m tensorboard.main --logdir=logs
 ```
----------------
\ No newline at end of file
+---------------
+# [INFO] Observation Manager: <ObservationManager> contains 1 groups.
++------------------------------------------------------------+
+| Active Observation Terms in Group: 'policy' (shape: (3099,)) |
++-----------+--------------------------------+---------------+
+|   Index   | Name                           |     Shape     |
++-----------+--------------------------------+---------------+
+|     0     | base_lin_vel                   |      (3,)     |
+|     1     | base_ang_vel                   |      (3,)     |
+|     2     | projected_gravity              |      (3,)     |
+|     3     | velocity_commands              |      (3,)     |
+|     4     | joint_pos                      |     (12,)     |
+|     5     | joint_vel                      |     (12,)     |
+|     6     | actions                        |     (12,)     |
+|     7     | height_scan                    |     (187,)    |
+|     8     | lidar_scan                     |    (2864,)    |
++-----------+--------------------------------+---------------+
\ No newline at end of file
diff --git a/real_bot/deploy_unitree.py b/real_bot/deploy_unitree.py
index 0047db6054..78a212731a 100644
--- a/real_bot/deploy_unitree.py
+++ b/real_bot/deploy_unitree.py
@@ -28,7 +28,8 @@ NUM_ACTIONS = 12
 HEIGHT_SCAN_SIZE = 187 # From env.yaml (1.6x1.0m grid with 0.1m resolution -> 17x11 points)
 
 # Default Joint Positions (Isaac Lab Order: FL, FR, RL, RR)
-# FL_hip, FL_thigh, FL_calf, FR_hip, FR_thigh, FR_calf, RL_hip, RL_thigh, RL_calf, RR_hip, RR_thigh, RR_calf
+# FL_hip, FL_thigh, FL_calf, FR_hip, FR_thigh, FR_calf 
+# RL_hip, RL_thigh, RL_calf, RR_hip, RR_thigh, RR_calf
 DEFAULT_JOINT_POS = np.array([
     0.1, 0.8, -1.5,   # FL
     -0.1, 0.8, -1.5,  # FR
@@ -41,18 +42,18 @@ DEFAULT_JOINT_POS = np.array([
 # Isaac Lab Order:   FL, FR, RL, RR
 
 # Unitree (FR, FL, RR, RL) -> Isaac (FL, FR, RL, RR)
-# FR(0-2) -> Isaac(3-5)
-# FL(3-5) -> Isaac(0-2)
-# RR(6-8) -> Isaac(9-11)
-# RL(9-11) -> Isaac(6-8)
-UNITREE_TO_ISAAC_IDX = [3, 4, 5, 0, 1, 2, 9, 10, 11, 6, 7, 8]
+# FR(0-2)   -> Isaac(3-5)
+# FL(3-5)   -> Isaac(0-2)
+# RR(6-8)   -> Isaac(9-11)
+# RL(9-11)  -> Isaac(6-8)
+UNITREE_TO_ISAAC_IDX = [3, 4, 5, 0, 1, 2, 9, 10, 11, 6, 7, 8] # for swapping pairs
 
 # Isaac (FL, FR, RL, RR) -> Unitree (FR, FL, RR, RL)
-# FL(0-2) -> Unitree(3-5)
-# FR(3-5) -> Unitree(0-2)
-# RL(6-8) -> Unitree(9-11)
-# RR(9-11) -> Unitree(6-8)
-ISAAC_TO_UNITREE_IDX = [3, 4, 5, 0, 1, 2, 9, 10, 11, 6, 7, 8] # Same mapping array works for swapping pairs
+# FL(0-2)   -> Unitree(3-5)
+# FR(3-5)   -> Unitree(0-2)
+# RL(6-8)   -> Unitree(9-11)
+# RR(9-11)  -> Unitree(6-8)
+ISAAC_TO_UNITREE_IDX = [3, 4, 5, 0, 1, 2, 9, 10, 11, 6, 7, 8] # for swapping pairs
 
 def get_network_interface(input_str):
     """
@@ -111,7 +112,7 @@ class RobotController:
         self.cmd_msg.levelFlag = 0xFF
         self.cmd_msg.gpio = 0
         for i in range(20):
-            self.cmd_msg.motorCmd[i].mode = 0x01    # Servo mode
+            self.cmd_msg.motorCmd[i].mode = 0x01    # Servo Low-cmd mode
             self.cmd_msg.motorCmd[i].q = 0.0        # Will be set later
             self.cmd_msg.motorCmd[i].dq = 0.0       # Will be set later
             self.cmd_msg.motorCmd[i].Kp = 0.0       # Will be set later
@@ -130,7 +131,7 @@ class RobotController:
             sys.exit(1)
 
         # State variables
-        self.last_actions = np.zeros(NUM_ACTIONS, dtype=np.float32)
+        self.last_actions = np.zeros(NUM_ACTIONS, dtype=np.float32) # Initialize last actions to zeros
         self.target_vel = np.array([0.0, 0.0, 0.0], dtype=np.float32) # vx, vy, wz
 
         print("Waiting for LowState...")
@@ -178,21 +179,20 @@ class RobotController:
         # 1. Base Linear Velocity (Estimated)
         # Real robot usually doesn't provide accurate base velocity without VIO/Lidar.
         # We use 0.0 or state estimator if available. For robustness, often 0.0 is used in blind deployment.
-        base_lin_vel = np.zeros(3, dtype=np.float32) 
+        base_lin_vel = np.zeros(3, dtype=np.float32) # Initialize to zeros
         
         # 2. Base Angular Velocity (Gyro)
-        base_ang_vel = np.array(state.imu.gyroscope, dtype=np.float32)
+        base_ang_vel = np.array(state.imu.gyroscope, dtype=np.float32) # Initialize to IMU's gyroscope
         
         # 3. Projected Gravity
-        projected_gravity = self.get_gravity_vector(state.imu.quaternion)
+        projected_gravity = self.get_gravity_vector(state.imu.quaternion) # Initialize to IMU's quaternion
         
-        # 4. Commands (Velocity)
+        # 4. Commands (Velocity) vx, vy, wz
         commands = self.target_vel
         
-        # 5. Joint Positions & 6. Joint Velocities
         # Read Raw (Unitree Order: FR, FL, RR, RL)
-        q_raw = np.array([m.q for m in state.motorState[:12]], dtype=np.float32)
-        dq_raw = np.array([m.dq for m in state.motorState[:12]], dtype=np.float32)
+        q_raw = np.array([m.q for m in state.motorState[:12]], dtype=np.float32)# 5. Joint Positions 
+        dq_raw = np.array([m.dq for m in state.motorState[:12]], dtype=np.float32) # 6. Joint Velocities
         
         # Convert to Isaac Order (FL, FR, RL, RR)
         q_isaac = q_raw[UNITREE_TO_ISAAC_IDX]
diff --git a/real_bot/sota_2025-11-06_11-43-35/events.out.tfevents.1762397031.DESKTOP-F5CN0L7.49960.0 b/real_bot/sota_2025-11-06_11-43-35/events.out.tfevents.1762397031.DESKTOP-F5CN0L7.49960.0
deleted file mode 100644
index 9f1f103f20..0000000000
Binary files a/real_bot/sota_2025-11-06_11-43-35/events.out.tfevents.1762397031.DESKTOP-F5CN0L7.49960.0 and /dev/null differ
diff --git a/real_bot/sota_2025-11-06_11-43-35/exported/policy.onnx b/real_bot/sota_2025-11-06_11-43-35/exported/policy.onnx
deleted file mode 100644
index b2b9a71047..0000000000
Binary files a/real_bot/sota_2025-11-06_11-43-35/exported/policy.onnx and /dev/null differ
diff --git a/real_bot/sota_2025-11-06_11-43-35/exported/policy.pt b/real_bot/sota_2025-11-06_11-43-35/exported/policy.pt
deleted file mode 100644
index dff3780290..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/exported/policy.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:b5ba7793e7bc0d6869b14056f24339dcd55a97e172fd2f4aab95f24b2c082641
-size 1158482
diff --git a/real_bot/sota_2025-11-06_11-43-35/git/IsaacLab.diff b/real_bot/sota_2025-11-06_11-43-35/git/IsaacLab.diff
deleted file mode 100644
index eef0655c4d..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/git/IsaacLab.diff
+++ /dev/null
@@ -1,313 +0,0 @@
---- git status ---
-On branch main
-Your branch is behind 'origin/main' by 6 commits, and can be fast-forwarded.
-  (use "git pull" to update your local branch)
-
-Changes not staged for commit:
-  (use "git add <file>..." to update what will be committed)
-  (use "git restore <file>..." to discard changes in working directory)
-	modified:   .gitignore
-	modified:   scripts/reinforcement_learning/rsl_rl/play.py
-	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/__init__.py
-	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/flat_env_cfg.py
-	modified:   source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
-
-Untracked files:
-  (use "git add <file>..." to include in what will be committed)
-	2.7.0+cu128
-	environment.yml.bak
-	scripts/pyramid_train.py
-	scripts/sensor_prepare.py
-
-no changes added to commit (use "git add" and/or "git commit -a") 
-
-
---- git diff ---
-diff --git a/.gitignore b/.gitignore
-index 08d2e8dee5..604a657363 100644
---- a/.gitignore
-+++ b/.gitignore
-@@ -69,3 +69,4 @@ tests/
- 
- # Docker history
- .isaac-lab-docker-history
-+.github/copilot-instructions.md
-diff --git a/scripts/reinforcement_learning/rsl_rl/play.py b/scripts/reinforcement_learning/rsl_rl/play.py
-index 11ef739946..91e2f0573b 100644
---- a/scripts/reinforcement_learning/rsl_rl/play.py
-+++ b/scripts/reinforcement_learning/rsl_rl/play.py
-@@ -34,6 +34,9 @@ parser.add_argument(
-     help="Use the pre-trained checkpoint from Nucleus.",
- )
- parser.add_argument("--real-time", action="store_true", default=False, help="Run in real-time, if possible.")
-+parser.add_argument("--log_joints", action="store_true", default=False, help="Log joint positions and velocities.")
-+parser.add_argument("--log_commands", action="store_true", default=False, help="Log velocity commands.")
-+parser.add_argument("--log_interval", type=int, default=10, help="Interval (in steps) for logging joint data.")
- # append RSL-RL cli arguments
- cli_args.add_rsl_rl_args(parser)
- # append AppLauncher cli args
-@@ -57,6 +60,8 @@ import gymnasium as gym
- import os
- import time
- import torch
-+import csv
-+import numpy as np
- 
- from rsl_rl.runners import DistillationRunner, OnPolicyRunner
- 
-@@ -174,6 +179,59 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
- 
-     dt = env.unwrapped.step_dt
- 
-+    # setup joint logging if requested
-+    joint_log_files = []
-+    joint_writers = []
-+    if args_cli.log_joints:
-+        joint_log_dir = os.path.join(log_dir, "joint_logs")
-+        os.makedirs(joint_log_dir, exist_ok=True)
-+        
-+        # Get joint names from the environment
-+        robot = env.unwrapped.scene["robot"]
-+        joint_names = robot.data.joint_names
-+        num_envs = env.unwrapped.scene.num_envs
-+        
-+        print(f"[INFO] Logging joint data for {num_envs} environments")
-+        print(f"[INFO] Joint names: {joint_names}")
-+        print(f"[INFO] Logging interval: {args_cli.log_interval} steps")
-+        
-+        # Create CSV file for each environment
-+        for env_idx in range(num_envs):
-+            log_file_path = os.path.join(joint_log_dir, f"env_{env_idx:03d}_joints.csv")
-+            log_file = open(log_file_path, 'w', newline='')
-+            joint_log_files.append(log_file)
-+            
-+            # Create CSV writer with header
-+            fieldnames = ['timestep', 'time'] + [f"{name}_pos" for name in joint_names] + [f"{name}_vel" for name in joint_names]
-+            writer = csv.DictWriter(log_file, fieldnames=fieldnames)
-+            writer.writeheader()
-+            joint_writers.append(writer)
-+    
-+    # setup command logging if requested
-+    command_log_files = []
-+    command_writers = []
-+    if args_cli.log_commands:
-+        command_log_dir = os.path.join(log_dir, "command_logs")
-+        os.makedirs(command_log_dir, exist_ok=True)
-+        
-+        num_envs = env.unwrapped.scene.num_envs
-+        
-+        print(f"[INFO] Logging command data for {num_envs} environments")
-+        print(f"[INFO] Command logging interval: {args_cli.log_interval} steps")
-+        
-+        # Create CSV file for each environment
-+        for env_idx in range(num_envs):
-+            log_file_path = os.path.join(command_log_dir, f"env_{env_idx:03d}_commands.csv")
-+            log_file = open(log_file_path, 'w', newline='')
-+            command_log_files.append(log_file)
-+            
-+            # Create CSV writer with header
-+            fieldnames = ['timestep', 'time', 'cmd_lin_vel_x', 'cmd_lin_vel_y', 'cmd_ang_vel_z', 
-+                         'actual_lin_vel_x', 'actual_lin_vel_y', 'actual_ang_vel_z']
-+            writer = csv.DictWriter(log_file, fieldnames=fieldnames)
-+            writer.writeheader()
-+            command_writers.append(writer)
-+
-     # reset environment
-     obs = env.get_observations()
-     timestep = 0
-@@ -186,8 +244,73 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
-             actions = policy(obs)
-             # env stepping
-             obs, _, _, _ = env.step(actions)
-+        
-+        # log joint data if requested
-+        if args_cli.log_joints and timestep % args_cli.log_interval == 0:
-+            robot = env.unwrapped.scene["robot"]
-+            joint_pos = robot.data.joint_pos.cpu().numpy()  # Shape: [num_envs, num_joints]
-+            joint_vel = robot.data.joint_vel.cpu().numpy()  # Shape: [num_envs, num_joints]
-+            current_time = timestep * dt
-+            
-+            # Log data for each environment
-+            for env_idx in range(env.unwrapped.scene.num_envs):
-+                row_data = {
-+                    'timestep': timestep,
-+                    'time': current_time
-+                }
-+                
-+                # Add joint positions
-+                for joint_idx, joint_name in enumerate(robot.data.joint_names):
-+                    row_data[f"{joint_name}_pos"] = joint_pos[env_idx, joint_idx]
-+                    row_data[f"{joint_name}_vel"] = joint_vel[env_idx, joint_idx]
-+                
-+                joint_writers[env_idx].writerow(row_data)
-+                # Flush to ensure data is written
-+                joint_log_files[env_idx].flush()
-+        
-+        # log command data if requested
-+        if args_cli.log_commands and timestep % args_cli.log_interval == 0:
-+            robot = env.unwrapped.scene["robot"]
-+            current_time = timestep * dt
-+            
-+            # Get velocity commands from the command manager
-+            if hasattr(env.unwrapped, 'command_manager') and hasattr(env.unwrapped.command_manager, 'get_command'):
-+                try:
-+                    # Try to get velocity commands
-+                    velocity_commands = env.unwrapped.command_manager.get_command("base_velocity")  # Shape: [num_envs, 3]
-+                    velocity_commands_np = velocity_commands.cpu().numpy()
-+                    
-+                    # Get actual robot velocities
-+                    actual_lin_vel = robot.data.root_lin_vel_b.cpu().numpy()  # Shape: [num_envs, 3]
-+                    actual_ang_vel = robot.data.root_ang_vel_b.cpu().numpy()  # Shape: [num_envs, 3]
-+                    
-+                    # Log data for each environment
-+                    for env_idx in range(env.unwrapped.scene.num_envs):
-+                        row_data = {
-+                            'timestep': timestep,
-+                            'time': current_time,
-+                            'cmd_lin_vel_x': velocity_commands_np[env_idx, 0],
-+                            'cmd_lin_vel_y': velocity_commands_np[env_idx, 1], 
-+                            'cmd_ang_vel_z': velocity_commands_np[env_idx, 2],
-+                            'actual_lin_vel_x': actual_lin_vel[env_idx, 0],
-+                            'actual_lin_vel_y': actual_lin_vel[env_idx, 1],
-+                            'actual_ang_vel_z': actual_ang_vel[env_idx, 2]
-+                        }
-+                        
-+                        command_writers[env_idx].writerow(row_data)
-+                        # Flush to ensure data is written
-+                        command_log_files[env_idx].flush()
-+                        
-+                except Exception as e:
-+                    if timestep == 0:  # Only print once
-+                        print(f"[WARNING] Could not access velocity commands: {e}")
-+            else:
-+                if timestep == 0:  # Only print once
-+                    print("[WARNING] Command manager not accessible for logging commands")
-+        
-+        timestep += 1
-+        
-         if args_cli.video:
--            timestep += 1
-             # Exit the play loop after recording one video
-             if timestep == args_cli.video_length:
-                 break
-@@ -197,6 +320,18 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
-         if args_cli.real_time and sleep_time > 0:
-             time.sleep(sleep_time)
- 
-+    # close joint log files if opened
-+    if args_cli.log_joints:
-+        for log_file in joint_log_files:
-+            log_file.close()
-+        print(f"[INFO] Joint logging completed. Files saved in: {joint_log_dir}")
-+    
-+    # close command log files if opened
-+    if args_cli.log_commands:
-+        for log_file in command_log_files:
-+            log_file.close()
-+        print(f"[INFO] Command logging completed. Files saved in: {command_log_dir}")
-+
-     # close the simulator
-     env.close()
- 
-diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/__init__.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/__init__.py
-index c9766e7d3a..2ff0cb384e 100644
---- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/__init__.py
-+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/__init__.py
-@@ -54,3 +54,28 @@ gym.register(
-         "skrl_cfg_entry_point": f"{agents.__name__}:skrl_rough_ppo_cfg.yaml",
-     },
- )
-+
-+gym.register(
-+    id="Isaac-Velocity-Stair-Unitree-Go2-v0",
-+    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-+    disable_env_checker=True,
-+    kwargs={
-+        "env_cfg_entry_point": f"{__name__}.stair_env_cfg:UnitreeGo2StairEnvCfg",
-+        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2RoughPPORunnerCfg",
-+        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_rough_ppo_cfg.yaml",
-+    },
-+)
-+
-+gym.register(
-+    id="Isaac-Velocity-Stair-Unitree-Go2-Play-v0",
-+    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-+    disable_env_checker=True,
-+    kwargs={
-+        "env_cfg_entry_point": f"{__name__}.stair_env_cfg:UnitreeGo2StairEnvCfg_PLAY",
-+        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2RoughPPORunnerCfg",
-+        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_rough_ppo_cfg.yaml",
-+    },
-+)
-+
-+
-+
-diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/flat_env_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/flat_env_cfg.py
-index fbcb4b3e52..00d44eb8f2 100644
---- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/flat_env_cfg.py
-+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/flat_env_cfg.py
-@@ -4,6 +4,8 @@
- # SPDX-License-Identifier: BSD-3-Clause
- 
- from isaaclab.utils import configclass
-+from isaaclab.managers import RewardTermCfg as RewTerm
-+from isaaclab.envs import mdp
- 
- from .rough_env_cfg import UnitreeGo2RoughEnvCfg
- 
-@@ -14,9 +16,23 @@ class UnitreeGo2FlatEnvCfg(UnitreeGo2RoughEnvCfg):
-         # post init of parent
-         super().__post_init__()
- 
--        # override rewards
--        self.rewards.flat_orientation_l2.weight = -2.5
--        self.rewards.feet_air_time.weight = 0.25
-+        # ============ ANTI-CRAWLING REWARD MODIFICATIONS ============
-+        # Significantly increase penalty for body tilting (was -2.5)
-+        self.rewards.flat_orientation_l2.weight = -10.0
-+        
-+        # Add penalty for maintaining wrong height (prevents crawling low)
-+        self.rewards.base_height_l2 = RewTerm(
-+            func=mdp.base_height_l2,
-+            weight=-5.0,
-+            params={"target_height": 0.34}  # Go2's normal standing height
-+        )
-+        
-+        # Increase penalties for unwanted movements to prevent crawling
-+        self.rewards.lin_vel_z_l2.weight = -4.0    # Prevent bouncing (was -2.0)
-+        self.rewards.ang_vel_xy_l2.weight = -0.2    # Prevent roll/pitch (was -0.05)
-+        
-+        # Enhanced foot rewards for proper walking (not shuffling/crawling)
-+        self.rewards.feet_air_time.weight = 0.5  # Increased from 0.25
- 
-         # change terrain to flat
-         self.scene.terrain.terrain_type = "plane"
-diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
-index 22fb69cff4..f0fab7f86a 100644
---- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
-+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
-@@ -3,7 +3,10 @@
- #
- # SPDX-License-Identifier: BSD-3-Clause
- 
-+import torch
- from isaaclab.utils import configclass
-+from isaaclab.managers import RewardTermCfg as RewTerm, SceneEntityCfg
-+from isaaclab.envs import mdp
- 
- from isaaclab_tasks.manager_based.locomotion.velocity.velocity_env_cfg import LocomotionVelocityRoughEnvCfg
- 
-@@ -29,6 +32,13 @@ class UnitreeGo2RoughEnvCfg(LocomotionVelocityRoughEnvCfg):
-         # reduce action scale
-         self.actions.joint_pos.scale = 0.25
- 
-+        # Body contact penalty - heavily penalize body touching ground
-+        self.rewards.body_contact_penalty = RewTerm(
-+            func=mdp.undesired_contacts,
-+            weight=-10.0,
-+            params={"threshold": 1.0, "sensor_cfg": SceneEntityCfg("contact_forces", body_names="base")}
-+        )        
-+
-         # event
-         self.events.push_robot = None
-         self.events.add_base_mass.params["mass_distribution_params"] = (-1.0, 3.0)
\ No newline at end of file
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_0.pt b/real_bot/sota_2025-11-06_11-43-35/model_0.pt
deleted file mode 100644
index 1a33e59e85..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_0.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:c8f113d979e1a6bea8d3b558573f6bca29e5c2d95ebfbb6b6b10a7cd5692134b
-size 6881559
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_100.pt b/real_bot/sota_2025-11-06_11-43-35/model_100.pt
deleted file mode 100644
index 77264a62b9..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_100.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:80519c1882b80d28c4a30c680b13063ba077572edf5ae38c8c8be42c57a5f7cc
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_150.pt b/real_bot/sota_2025-11-06_11-43-35/model_150.pt
deleted file mode 100644
index e52b57b1ae..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_150.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:46c5d41d8a3cbdf97dcb0e53766ec5aedd1fec0c601ce243b0854c259dad0536
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_200.pt b/real_bot/sota_2025-11-06_11-43-35/model_200.pt
deleted file mode 100644
index 84f55bbf5f..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_200.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:5f5fdbf5c738230189276b1e8a297d7b160751baed6d58447d94bb7d5b3945af
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_250.pt b/real_bot/sota_2025-11-06_11-43-35/model_250.pt
deleted file mode 100644
index 8e4b94cbe7..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_250.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:9024a55240b9acb87989b5ad6f73dbaff622e7dafaa8ed8a9c0c37bae1e0b21a
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_300.pt b/real_bot/sota_2025-11-06_11-43-35/model_300.pt
deleted file mode 100644
index 8b998a2976..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_300.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:ffd2400d0ec397911fe0e67af69e3ae71cdca7bce85de45be74f3029f6f2a91c
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_350.pt b/real_bot/sota_2025-11-06_11-43-35/model_350.pt
deleted file mode 100644
index 089534ec6b..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_350.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:532deb1304a63e9aca95ef7821e3628b5d3b752cc6b73116eab2c332390168ee
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_400.pt b/real_bot/sota_2025-11-06_11-43-35/model_400.pt
deleted file mode 100644
index 0c4793b480..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_400.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:392d993f98b23f62fce23f456fd2884f89a7e21673c46e959452cc4cf252bc13
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_450.pt b/real_bot/sota_2025-11-06_11-43-35/model_450.pt
deleted file mode 100644
index 7bfb93bae8..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_450.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:219220ba4161958c239d2e7e0e922fbc37ac96e5d971500718227ac95a49b83c
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_50.pt b/real_bot/sota_2025-11-06_11-43-35/model_50.pt
deleted file mode 100644
index d50232d651..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_50.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:28d9629b3e08245f193b6f6ad6d74b128de4f0c9125daf3054509564902faf9e
-size 6882145
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_500.pt b/real_bot/sota_2025-11-06_11-43-35/model_500.pt
deleted file mode 100644
index e252645fd3..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_500.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:9087e831643dec58460f2e0ae942b877a886fbc701057124578a23d2fe7d5323
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_550.pt b/real_bot/sota_2025-11-06_11-43-35/model_550.pt
deleted file mode 100644
index 7ee9180549..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_550.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:1ac33ca1a551b829210df03162d27de370af3a1206622818eeec3b7bbcb78a01
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_600.pt b/real_bot/sota_2025-11-06_11-43-35/model_600.pt
deleted file mode 100644
index f12a989c95..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_600.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:65f166c3aec6768bef74d53d17bc33dd9213bb5e23685b85bd68f599ee9a31b1
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_650.pt b/real_bot/sota_2025-11-06_11-43-35/model_650.pt
deleted file mode 100644
index d6b6b48243..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_650.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:c2d317728c4f24d28c73f53c0606930fa1e7a83dab38ed0e0c1de98b93dd634b
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_700.pt b/real_bot/sota_2025-11-06_11-43-35/model_700.pt
deleted file mode 100644
index 4d360569ed..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_700.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:e0f18e17546c03cf40cc5f9d9365caf59b24a39466b4e81a4c91153422d24c12
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_750.pt b/real_bot/sota_2025-11-06_11-43-35/model_750.pt
deleted file mode 100644
index 95b95aacc6..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_750.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:91808c6836975e62a45f103a928bff27290f28e75d3ac2703e1e4e19f7cbc997
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_800.pt b/real_bot/sota_2025-11-06_11-43-35/model_800.pt
deleted file mode 100644
index 27e2926649..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_800.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:eee7b39117c3985f7db1bdd36b7152b5ee604cdda9ea010b6fd689f0d555cd55
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_850.pt b/real_bot/sota_2025-11-06_11-43-35/model_850.pt
deleted file mode 100644
index dadd4e524f..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_850.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:51e9f6ac3f610af33cb5574ee021a9be1b58886fd006cec60c75b13738e59759
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_900.pt b/real_bot/sota_2025-11-06_11-43-35/model_900.pt
deleted file mode 100644
index 252b3571df..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_900.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:bfaad9cd89426e6f06f180e904f4374dedc492780646e6f85fc7dc55a70134b1
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_950.pt b/real_bot/sota_2025-11-06_11-43-35/model_950.pt
deleted file mode 100644
index a291c3de05..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_950.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:a4eb6eec4a9e5ecc158fc75ac6231b0dd91ca93166ed6a7227560e99278d5417
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/model_999.pt b/real_bot/sota_2025-11-06_11-43-35/model_999.pt
deleted file mode 100644
index f34ae86e06..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/model_999.pt
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:028728edee84be8701bef6670d87abf9aa828f8f75a9fe03cc4b5cbc079d0664
-size 6882219
diff --git a/real_bot/sota_2025-11-06_11-43-35/params/agent.yaml b/real_bot/sota_2025-11-06_11-43-35/params/agent.yaml
deleted file mode 100644
index 58b272d1de..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/params/agent.yaml
+++ /dev/null
@@ -1,49 +0,0 @@
-seed: 42
-device: cuda:0
-num_steps_per_env: 24
-max_iterations: 1000
-empirical_normalization: null
-obs_groups: {}
-clip_actions: null
-save_interval: 50
-experiment_name: unitree_go2_rough
-run_name: ''
-logger: tensorboard
-neptune_project: isaaclab
-wandb_project: isaaclab
-resume: false
-load_run: .*
-load_checkpoint: model_.*.pt
-class_name: OnPolicyRunner
-policy:
-  class_name: ActorCritic
-  init_noise_std: 1.0
-  noise_std_type: scalar
-  actor_obs_normalization: false
-  critic_obs_normalization: false
-  actor_hidden_dims:
-  - 512
-  - 256
-  - 128
-  critic_hidden_dims:
-  - 512
-  - 256
-  - 128
-  activation: elu
-algorithm:
-  class_name: PPO
-  num_learning_epochs: 5
-  num_mini_batches: 4
-  learning_rate: 0.001
-  schedule: adaptive
-  gamma: 0.99
-  lam: 0.95
-  entropy_coef: 0.01
-  desired_kl: 0.01
-  max_grad_norm: 1.0
-  value_loss_coef: 1.0
-  use_clipped_value_loss: true
-  clip_param: 0.2
-  normalize_advantage_per_mini_batch: false
-  rnd_cfg: null
-  symmetry_cfg: null
diff --git a/real_bot/sota_2025-11-06_11-43-35/params/env.yaml b/real_bot/sota_2025-11-06_11-43-35/params/env.yaml
deleted file mode 100644
index fe5eb62ca5..0000000000
--- a/real_bot/sota_2025-11-06_11-43-35/params/env.yaml
+++ /dev/null
@@ -1,1047 +0,0 @@
-viewer:
-  eye: !!python/tuple
-  - 7.5
-  - 7.5
-  - 7.5
-  lookat: !!python/tuple
-  - 0.0
-  - 0.0
-  - 0.0
-  cam_prim_path: /OmniverseKit_Persp
-  resolution: !!python/tuple
-  - 1280
-  - 720
-  origin_type: world
-  env_index: 0
-  asset_name: null
-  body_name: null
-sim:
-  physics_prim_path: /physicsScene
-  device: cuda:0
-  dt: 0.005
-  render_interval: 4
-  gravity: !!python/tuple
-  - 0.0
-  - 0.0
-  - -9.81
-  enable_scene_query_support: false
-  use_fabric: true
-  physx:
-    solver_type: 1
-    min_position_iteration_count: 1
-    max_position_iteration_count: 255
-    min_velocity_iteration_count: 0
-    max_velocity_iteration_count: 255
-    enable_ccd: false
-    enable_stabilization: false
-    enable_enhanced_determinism: false
-    bounce_threshold_velocity: 0.5
-    friction_offset_threshold: 0.04
-    friction_correlation_distance: 0.025
-    gpu_max_rigid_contact_count: 8388608
-    gpu_max_rigid_patch_count: 327680
-    gpu_found_lost_pairs_capacity: 2097152
-    gpu_found_lost_aggregate_pairs_capacity: 33554432
-    gpu_total_aggregate_pairs_capacity: 2097152
-    gpu_collision_stack_size: 67108864
-    gpu_heap_capacity: 67108864
-    gpu_temp_buffer_capacity: 16777216
-    gpu_max_num_partitions: 8
-    gpu_max_soft_body_contacts: 1048576
-    gpu_max_particle_contacts: 1048576
-    solve_articulation_contact_last: false
-  physics_material:
-    func: isaaclab.sim.spawners.materials.physics_materials:spawn_rigid_body_material
-    static_friction: 1.0
-    dynamic_friction: 1.0
-    restitution: 0.0
-    friction_combine_mode: multiply
-    restitution_combine_mode: multiply
-    compliant_contact_stiffness: 0.0
-    compliant_contact_damping: 0.0
-  render:
-    enable_translucency: null
-    enable_reflections: null
-    enable_global_illumination: null
-    antialiasing_mode: null
-    enable_dlssg: null
-    enable_dl_denoiser: null
-    dlss_mode: null
-    enable_direct_lighting: null
-    samples_per_pixel: null
-    enable_shadows: null
-    enable_ambient_occlusion: null
-    dome_light_upper_lower_strategy: null
-    carb_settings: null
-    rendering_mode: null
-  create_stage_in_memory: false
-ui_window_class_type: isaaclab.envs.ui.manager_based_rl_env_window:ManagerBasedRLEnvWindow
-seed: 42
-decimation: 4
-scene:
-  num_envs: 4096
-  env_spacing: 2.5
-  lazy_sensor_update: true
-  replicate_physics: true
-  filter_collisions: true
-  clone_in_fabric: false
-  robot:
-    class_type: isaaclab.assets.articulation.articulation:Articulation
-    prim_path: /World/envs/env_.*/Robot
-    spawn:
-      func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
-      visible: true
-      semantic_tags: null
-      copy_from_source: true
-      mass_props: null
-      deformable_props: null
-      rigid_props:
-        rigid_body_enabled: null
-        kinematic_enabled: null
-        disable_gravity: false
-        linear_damping: 0.0
-        angular_damping: 0.0
-        max_linear_velocity: 1000.0
-        max_angular_velocity: 1000.0
-        max_depenetration_velocity: 1.0
-        max_contact_impulse: null
-        enable_gyroscopic_forces: null
-        retain_accelerations: false
-        solver_position_iteration_count: null
-        solver_velocity_iteration_count: null
-        sleep_threshold: null
-        stabilization_threshold: null
-      collision_props: null
-      activate_contact_sensors: true
-      scale: null
-      articulation_props:
-        articulation_enabled: null
-        enabled_self_collisions: false
-        solver_position_iteration_count: 4
-        solver_velocity_iteration_count: 0
-        sleep_threshold: null
-        stabilization_threshold: null
-        fix_root_link: null
-      fixed_tendons_props: null
-      spatial_tendons_props: null
-      joint_drive_props: null
-      visual_material_path: material
-      visual_material: null
-      usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Robots/Unitree/Go2/go2.usd
-      variants: null
-    init_state:
-      pos: !!python/tuple
-      - 0.0
-      - 0.0
-      - 0.4
-      rot: !!python/tuple
-      - 1.0
-      - 0.0
-      - 0.0
-      - 0.0
-      lin_vel: !!python/tuple
-      - 0.0
-      - 0.0
-      - 0.0
-      ang_vel: !!python/tuple
-      - 0.0
-      - 0.0
-      - 0.0
-      joint_pos:
-        .*L_hip_joint: 0.1
-        .*R_hip_joint: -0.1
-        F[L,R]_thigh_joint: 0.8
-        R[L,R]_thigh_joint: 1.0
-        .*_calf_joint: -1.5
-      joint_vel:
-        .*: 0.0
-    collision_group: 0
-    debug_vis: false
-    articulation_root_prim_path: null
-    soft_joint_pos_limit_factor: 0.9
-    actuators:
-      base_legs:
-        class_type: isaaclab.actuators.actuator_pd:DCMotor
-        joint_names_expr:
-        - .*_hip_joint
-        - .*_thigh_joint
-        - .*_calf_joint
-        effort_limit: 23.5
-        velocity_limit: 30.0
-        effort_limit_sim: null
-        velocity_limit_sim: null
-        stiffness: 25.0
-        damping: 0.5
-        armature: null
-        friction: 0.0
-        dynamic_friction: null
-        viscous_friction: null
-        saturation_effort: 23.5
-    actuator_value_resolution_debug_print: false
-  terrain:
-    class_type: isaaclab.terrains.terrain_importer:TerrainImporter
-    collision_group: -1
-    prim_path: /World/ground
-    num_envs: 4096
-    terrain_type: generator
-    terrain_generator:
-      class_type: isaaclab.terrains.terrain_generator:TerrainGenerator
-      seed: null
-      curriculum: true
-      size: !!python/tuple
-      - 8.0
-      - 8.0
-      border_width: 20.0
-      border_height: 1.0
-      num_rows: 10
-      num_cols: 20
-      color_scheme: none
-      horizontal_scale: 0.1
-      vertical_scale: 0.005
-      slope_threshold: 0.75
-      sub_terrains:
-        pyramid_stairs:
-          function: isaaclab.terrains.trimesh.mesh_terrains:pyramid_stairs_terrain
-          proportion: 0.2
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          border_width: 1.0
-          step_height_range: !!python/tuple
-          - 0.05
-          - 0.23
-          step_width: 0.3
-          platform_width: 3.0
-          holes: false
-        pyramid_stairs_inv:
-          function: isaaclab.terrains.trimesh.mesh_terrains:inverted_pyramid_stairs_terrain
-          proportion: 0.2
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          border_width: 1.0
-          step_height_range: !!python/tuple
-          - 0.05
-          - 0.23
-          step_width: 0.3
-          platform_width: 3.0
-          holes: false
-        boxes:
-          function: isaaclab.terrains.trimesh.mesh_terrains:random_grid_terrain
-          proportion: 0.2
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          grid_width: 0.45
-          grid_height_range: !!python/tuple
-          - 0.025
-          - 0.1
-          platform_width: 2.0
-          holes: false
-        random_rough:
-          function: isaaclab.terrains.height_field.hf_terrains:random_uniform_terrain
-          proportion: 0.2
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          border_width: 0.25
-          horizontal_scale: 0.1
-          vertical_scale: 0.005
-          slope_threshold: 0.75
-          noise_range: !!python/tuple
-          - 0.01
-          - 0.06
-          noise_step: 0.01
-          downsampled_scale: null
-        hf_pyramid_slope:
-          function: isaaclab.terrains.height_field.hf_terrains:pyramid_sloped_terrain
-          proportion: 0.1
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          border_width: 0.25
-          horizontal_scale: 0.1
-          vertical_scale: 0.005
-          slope_threshold: 0.75
-          slope_range: !!python/tuple
-          - 0.0
-          - 0.4
-          platform_width: 2.0
-          inverted: false
-        hf_pyramid_slope_inv:
-          function: isaaclab.terrains.height_field.hf_terrains:pyramid_sloped_terrain
-          proportion: 0.1
-          size: !!python/tuple
-          - 8.0
-          - 8.0
-          flat_patch_sampling: null
-          border_width: 0.25
-          horizontal_scale: 0.1
-          vertical_scale: 0.005
-          slope_threshold: 0.75
-          slope_range: !!python/tuple
-          - 0.0
-          - 0.4
-          platform_width: 2.0
-          inverted: true
-      difficulty_range: !!python/tuple
-      - 0.0
-      - 1.0
-      use_cache: false
-      cache_dir: /tmp/isaaclab/terrains
-    usd_path: null
-    env_spacing: 2.5
-    visual_material:
-      func: isaaclab.sim.spawners.materials.visual_materials:spawn_from_mdl_file
-      mdl_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Materials/TilesMarbleSpiderWhiteBrickBondHoned/TilesMarbleSpiderWhiteBrickBondHoned.mdl
-      project_uvw: true
-      albedo_brightness: null
-      texture_scale: !!python/tuple
-      - 0.25
-      - 0.25
-    physics_material:
-      func: isaaclab.sim.spawners.materials.physics_materials:spawn_rigid_body_material
-      static_friction: 1.0
-      dynamic_friction: 1.0
-      restitution: 0.0
-      friction_combine_mode: multiply
-      restitution_combine_mode: multiply
-      compliant_contact_stiffness: 0.0
-      compliant_contact_damping: 0.0
-    max_init_terrain_level: 5
-    debug_vis: false
-  height_scanner:
-    class_type: isaaclab.sensors.ray_caster.ray_caster:RayCaster
-    prim_path: /World/envs/env_.*/Robot/base
-    update_period: 0.02
-    history_length: 0
-    debug_vis: false
-    mesh_prim_paths:
-    - /World/ground
-    offset:
-      pos: !!python/tuple
-      - 0.0
-      - 0.0
-      - 20.0
-      rot: !!python/tuple
-      - 1.0
-      - 0.0
-      - 0.0
-      - 0.0
-    attach_yaw_only: null
-    ray_alignment: yaw
-    pattern_cfg:
-      func: isaaclab.sensors.ray_caster.patterns.patterns:grid_pattern
-      resolution: 0.1
-      size:
-      - 1.6
-      - 1.0
-      direction: !!python/tuple
-      - 0.0
-      - 0.0
-      - -1.0
-      ordering: xy
-    max_distance: 1000000.0
-    drift_range: !!python/tuple
-    - 0.0
-    - 0.0
-    ray_cast_drift_range:
-      x: !!python/tuple
-      - 0.0
-      - 0.0
-      y: !!python/tuple
-      - 0.0
-      - 0.0
-      z: !!python/tuple
-      - 0.0
-      - 0.0
-    visualizer_cfg:
-      prim_path: /Visuals/RayCaster
-      markers:
-        hit:
-          func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
-          visible: true
-          semantic_tags: null
-          copy_from_source: true
-          mass_props: null
-          rigid_props: null
-          collision_props: null
-          activate_contact_sensors: false
-          visual_material_path: material
-          visual_material:
-            func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
-            diffuse_color: !!python/tuple
-            - 1.0
-            - 0.0
-            - 0.0
-            emissive_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 0.0
-            roughness: 0.5
-            metallic: 0.0
-            opacity: 1.0
-          physics_material_path: material
-          physics_material: null
-          radius: 0.02
-  contact_forces:
-    class_type: isaaclab.sensors.contact_sensor.contact_sensor:ContactSensor
-    prim_path: /World/envs/env_.*/Robot/.*
-    update_period: 0.005
-    history_length: 3
-    debug_vis: false
-    track_pose: false
-    track_contact_points: false
-    max_contact_data_count_per_prim: 4
-    track_air_time: true
-    force_threshold: 1.0
-    filter_prim_paths_expr: []
-    visualizer_cfg:
-      prim_path: /Visuals/ContactSensor
-      markers:
-        contact:
-          func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
-          visible: true
-          semantic_tags: null
-          copy_from_source: true
-          mass_props: null
-          rigid_props: null
-          collision_props: null
-          activate_contact_sensors: false
-          visual_material_path: material
-          visual_material:
-            func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
-            diffuse_color: !!python/tuple
-            - 1.0
-            - 0.0
-            - 0.0
-            emissive_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 0.0
-            roughness: 0.5
-            metallic: 0.0
-            opacity: 1.0
-          physics_material_path: material
-          physics_material: null
-          radius: 0.02
-        no_contact:
-          func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
-          visible: false
-          semantic_tags: null
-          copy_from_source: true
-          mass_props: null
-          rigid_props: null
-          collision_props: null
-          activate_contact_sensors: false
-          visual_material_path: material
-          visual_material:
-            func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
-            diffuse_color: !!python/tuple
-            - 0.0
-            - 1.0
-            - 0.0
-            emissive_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 0.0
-            roughness: 0.5
-            metallic: 0.0
-            opacity: 1.0
-          physics_material_path: material
-          physics_material: null
-          radius: 0.02
-  sky_light:
-    class_type: null
-    prim_path: /World/skyLight
-    spawn:
-      func: isaaclab.sim.spawners.lights.lights:spawn_light
-      visible: true
-      semantic_tags: null
-      copy_from_source: true
-      prim_type: DomeLight
-      color: !!python/tuple
-      - 1.0
-      - 1.0
-      - 1.0
-      enable_color_temperature: false
-      color_temperature: 6500.0
-      normalize: false
-      exposure: 0.0
-      intensity: 750.0
-      texture_file: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Materials/Textures/Skies/PolyHaven/kloofendal_43d_clear_puresky_4k.hdr
-      texture_format: automatic
-      visible_in_primary_ray: true
-    init_state:
-      pos: !!python/tuple
-      - 0.0
-      - 0.0
-      - 0.0
-      rot: !!python/tuple
-      - 1.0
-      - 0.0
-      - 0.0
-      - 0.0
-    collision_group: 0
-    debug_vis: false
-recorders:
-  dataset_file_handler_class_type: isaaclab.utils.datasets.hdf5_dataset_file_handler:HDF5DatasetFileHandler
-  dataset_export_dir_path: /tmp/isaaclab/logs
-  dataset_filename: dataset
-  dataset_export_mode:
-    _value_: 1
-    _name_: EXPORT_ALL
-    _sort_order_: 1
-  export_in_record_pre_reset: true
-observations:
-  policy:
-    concatenate_terms: true
-    concatenate_dim: -1
-    enable_corruption: true
-    history_length: null
-    flatten_history_dim: true
-    base_lin_vel:
-      func: isaaclab.envs.mdp.observations:base_lin_vel
-      params: {}
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -0.1
-        n_max: 0.1
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    base_ang_vel:
-      func: isaaclab.envs.mdp.observations:base_ang_vel
-      params: {}
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -0.2
-        n_max: 0.2
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    projected_gravity:
-      func: isaaclab.envs.mdp.observations:projected_gravity
-      params: {}
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -0.05
-        n_max: 0.05
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    velocity_commands:
-      func: isaaclab.envs.mdp.observations:generated_commands
-      params:
-        command_name: base_velocity
-      modifiers: null
-      noise: null
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    joint_pos:
-      func: isaaclab.envs.mdp.observations:joint_pos_rel
-      params: {}
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -0.01
-        n_max: 0.01
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    joint_vel:
-      func: isaaclab.envs.mdp.observations:joint_vel_rel
-      params: {}
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -1.5
-        n_max: 1.5
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    actions:
-      func: isaaclab.envs.mdp.observations:last_action
-      params: {}
-      modifiers: null
-      noise: null
-      clip: null
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-    height_scan:
-      func: isaaclab.envs.mdp.observations:height_scan
-      params:
-        sensor_cfg:
-          name: height_scanner
-          joint_names: null
-          joint_ids: !!python/object/apply:builtins.slice
-          - null
-          - null
-          - null
-          fixed_tendon_names: null
-          fixed_tendon_ids: !!python/object/apply:builtins.slice
-          - null
-          - null
-          - null
-          body_names: null
-          body_ids: !!python/object/apply:builtins.slice
-          - null
-          - null
-          - null
-          object_collection_names: null
-          object_collection_ids: !!python/object/apply:builtins.slice
-          - null
-          - null
-          - null
-          preserve_order: false
-      modifiers: null
-      noise:
-        func: isaaclab.utils.noise.noise_model:uniform_noise
-        operation: add
-        n_min: -0.1
-        n_max: 0.1
-      clip: !!python/tuple
-      - -1.0
-      - 1.0
-      scale: null
-      history_length: 0
-      flatten_history_dim: true
-actions:
-  joint_pos:
-    class_type: isaaclab.envs.mdp.actions.joint_actions:JointPositionAction
-    asset_name: robot
-    debug_vis: false
-    clip: null
-    joint_names:
-    - .*
-    scale: 0.25
-    offset: 0.0
-    preserve_order: false
-    use_default_offset: true
-events:
-  physics_material:
-    func: isaaclab.envs.mdp.events:randomize_rigid_body_material
-    params:
-      asset_cfg:
-        name: robot
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: .*
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-      static_friction_range: !!python/tuple
-      - 0.8
-      - 0.8
-      dynamic_friction_range: !!python/tuple
-      - 0.6
-      - 0.6
-      restitution_range: !!python/tuple
-      - 0.0
-      - 0.0
-      num_buckets: 64
-    mode: startup
-    interval_range_s: null
-    is_global_time: false
-    min_step_count_between_reset: 0
-  add_base_mass:
-    func: isaaclab.envs.mdp.events:randomize_rigid_body_mass
-    params:
-      asset_cfg:
-        name: robot
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: base
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-      mass_distribution_params: !!python/tuple
-      - -1.0
-      - 3.0
-      operation: add
-    mode: startup
-    interval_range_s: null
-    is_global_time: false
-    min_step_count_between_reset: 0
-  base_com: null
-  base_external_force_torque:
-    func: isaaclab.envs.mdp.events:apply_external_force_torque
-    params:
-      asset_cfg:
-        name: robot
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: base
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-      force_range: !!python/tuple
-      - 0.0
-      - 0.0
-      torque_range: !!python/tuple
-      - -0.0
-      - 0.0
-    mode: reset
-    interval_range_s: null
-    is_global_time: false
-    min_step_count_between_reset: 0
-  reset_base:
-    func: isaaclab.envs.mdp.events:reset_root_state_uniform
-    params:
-      pose_range:
-        x: !!python/tuple
-        - -0.5
-        - 0.5
-        y: !!python/tuple
-        - -0.5
-        - 0.5
-        yaw: !!python/tuple
-        - -3.14
-        - 3.14
-      velocity_range:
-        x: !!python/tuple
-        - 0.0
-        - 0.0
-        y: !!python/tuple
-        - 0.0
-        - 0.0
-        z: !!python/tuple
-        - 0.0
-        - 0.0
-        roll: !!python/tuple
-        - 0.0
-        - 0.0
-        pitch: !!python/tuple
-        - 0.0
-        - 0.0
-        yaw: !!python/tuple
-        - 0.0
-        - 0.0
-    mode: reset
-    interval_range_s: null
-    is_global_time: false
-    min_step_count_between_reset: 0
-  reset_robot_joints:
-    func: isaaclab.envs.mdp.events:reset_joints_by_scale
-    params:
-      position_range: !!python/tuple
-      - 1.0
-      - 1.0
-      velocity_range: !!python/tuple
-      - 0.0
-      - 0.0
-    mode: reset
-    interval_range_s: null
-    is_global_time: false
-    min_step_count_between_reset: 0
-  push_robot: null
-rerender_on_reset: false
-wait_for_textures: true
-xr: null
-teleop_devices:
-  devices: {}
-export_io_descriptors: false
-log_dir: C:\Users\User\github\IsaacLab\logs\rsl_rl\unitree_go2_rough\2025-11-06_11-43-35
-is_finite_horizon: false
-episode_length_s: 20.0
-rewards:
-  track_lin_vel_xy_exp:
-    func: isaaclab.envs.mdp.rewards:track_lin_vel_xy_exp
-    params:
-      command_name: base_velocity
-      std: 0.5
-    weight: 1.5
-  track_ang_vel_z_exp:
-    func: isaaclab.envs.mdp.rewards:track_ang_vel_z_exp
-    params:
-      command_name: base_velocity
-      std: 0.5
-    weight: 0.75
-  lin_vel_z_l2:
-    func: isaaclab.envs.mdp.rewards:lin_vel_z_l2
-    params: {}
-    weight: -2.0
-  ang_vel_xy_l2:
-    func: isaaclab.envs.mdp.rewards:ang_vel_xy_l2
-    params: {}
-    weight: -0.05
-  dof_torques_l2:
-    func: isaaclab.envs.mdp.rewards:joint_torques_l2
-    params: {}
-    weight: -0.0002
-  dof_acc_l2:
-    func: isaaclab.envs.mdp.rewards:joint_acc_l2
-    params: {}
-    weight: -2.5e-07
-  action_rate_l2:
-    func: isaaclab.envs.mdp.rewards:action_rate_l2
-    params: {}
-    weight: -0.01
-  feet_air_time:
-    func: isaaclab_tasks.manager_based.locomotion.velocity.mdp.rewards:feet_air_time
-    params:
-      sensor_cfg:
-        name: contact_forces
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: .*_foot
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-      command_name: base_velocity
-      threshold: 0.5
-    weight: 0.01
-  undesired_contacts: null
-  flat_orientation_l2:
-    func: isaaclab.envs.mdp.rewards:flat_orientation_l2
-    params: {}
-    weight: 0.0
-  dof_pos_limits:
-    func: isaaclab.envs.mdp.rewards:joint_pos_limits
-    params: {}
-    weight: 0.0
-  body_contact_penalty:
-    func: isaaclab.envs.mdp.rewards:undesired_contacts
-    params:
-      threshold: 1.0
-      sensor_cfg:
-        name: contact_forces
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: base
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-    weight: -10.0
-terminations:
-  time_out:
-    func: isaaclab.envs.mdp.terminations:time_out
-    params: {}
-    time_out: true
-  base_contact:
-    func: isaaclab.envs.mdp.terminations:illegal_contact
-    params:
-      sensor_cfg:
-        name: contact_forces
-        joint_names: null
-        joint_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        fixed_tendon_names: null
-        fixed_tendon_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        body_names: base
-        body_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        object_collection_names: null
-        object_collection_ids: !!python/object/apply:builtins.slice
-        - null
-        - null
-        - null
-        preserve_order: false
-      threshold: 1.0
-    time_out: false
-curriculum:
-  terrain_levels:
-    func: isaaclab_tasks.manager_based.locomotion.velocity.mdp.curriculums:terrain_levels_vel
-    params: {}
-commands:
-  base_velocity:
-    class_type: isaaclab.envs.mdp.commands.velocity_command:UniformVelocityCommand
-    resampling_time_range: !!python/tuple
-    - 10.0
-    - 10.0
-    debug_vis: true
-    asset_name: robot
-    heading_command: true
-    heading_control_stiffness: 0.5
-    rel_standing_envs: 0.02
-    rel_heading_envs: 1.0
-    ranges:
-      lin_vel_x: !!python/tuple
-      - -1.0
-      - 1.0
-      lin_vel_y: !!python/tuple
-      - -1.0
-      - 1.0
-      ang_vel_z: !!python/tuple
-      - -1.0
-      - 1.0
-      heading: !!python/tuple
-      - -3.141592653589793
-      - 3.141592653589793
-    goal_vel_visualizer_cfg:
-      prim_path: /Visuals/Command/velocity_goal
-      markers:
-        arrow:
-          func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
-          visible: true
-          semantic_tags: null
-          copy_from_source: true
-          mass_props: null
-          deformable_props: null
-          rigid_props: null
-          collision_props: null
-          activate_contact_sensors: false
-          scale: !!python/tuple
-          - 0.5
-          - 0.5
-          - 0.5
-          articulation_props: null
-          fixed_tendons_props: null
-          spatial_tendons_props: null
-          joint_drive_props: null
-          visual_material_path: material
-          visual_material:
-            func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
-            diffuse_color: !!python/tuple
-            - 0.0
-            - 1.0
-            - 0.0
-            emissive_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 0.0
-            roughness: 0.5
-            metallic: 0.0
-            opacity: 1.0
-          usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Props/UIElements/arrow_x.usd
-          variants: null
-    current_vel_visualizer_cfg:
-      prim_path: /Visuals/Command/velocity_current
-      markers:
-        arrow:
-          func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
-          visible: true
-          semantic_tags: null
-          copy_from_source: true
-          mass_props: null
-          deformable_props: null
-          rigid_props: null
-          collision_props: null
-          activate_contact_sensors: false
-          scale: !!python/tuple
-          - 0.5
-          - 0.5
-          - 0.5
-          articulation_props: null
-          fixed_tendons_props: null
-          spatial_tendons_props: null
-          joint_drive_props: null
-          visual_material_path: material
-          visual_material:
-            func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
-            diffuse_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 1.0
-            emissive_color: !!python/tuple
-            - 0.0
-            - 0.0
-            - 0.0
-            roughness: 0.5
-            metallic: 0.0
-            opacity: 1.0
-          usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Props/UIElements/arrow_x.usd
-          variants: null
diff --git a/scripts/reinforcement_learning/rsl_rl/play.py b/scripts/reinforcement_learning/rsl_rl/play.py
index ffee9ded52..be9bab048e 100644
--- a/scripts/reinforcement_learning/rsl_rl/play.py
+++ b/scripts/reinforcement_learning/rsl_rl/play.py
@@ -61,6 +61,7 @@ import os
 import time
 import torch
 import csv
+import numpy as np
 
 from rsl_rl.runners import DistillationRunner, OnPolicyRunner
 
@@ -75,6 +76,8 @@ from isaaclab.utils.assets import retrieve_file_path
 from isaaclab.utils.dict import print_dict
 from isaaclab.utils.pretrained_checkpoint import get_published_pretrained_checkpoint
 
+# from isaaclab.devices import Se3Keyboard,Se3KeyboardCfg
+
 from isaaclab_rl.rsl_rl import RslRlBaseRunnerCfg, RslRlVecEnvWrapper, export_policy_as_jit, export_policy_as_onnx
 
 import isaaclab_tasks  # noqa: F401
@@ -154,6 +157,13 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
     # obtain the trained policy for inference
     policy = runner.get_inference_policy(device=env.unwrapped.device)
 
+    # # === [추가 1] 키보드 컨트롤러 설정 ===
+    # # pos_sensitivity: 이동 속도 민감도 (m/s)
+    # # rot_sensitivity: 회전 속도 민감도 (rad/s)
+    # teleop_interface = Se3Keyboard(Se3KeyboardCfg(sim_device=env.unwrapped.device, pos_sensitivity=1.0, rot_sensitivity=1.0))
+    # print(teleop_interface) # 터미널에 조작법(W,A,S,D...)이 출력됩니다.
+    # # ==================================
+
     # extract the neural network module
     # we do this in a try-except to maintain backwards compatibility.
     try:
@@ -201,7 +211,11 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
             joint_log_files.append(log_file)
             
             # Create CSV writer with header
-            fieldnames = ['timestep', 'time'] + [f"{name}_pos" for name in joint_names] + [f"{name}_vel" for name in joint_names]
+            # Added target_pos columns
+            fieldnames = ['timestep', 'time'] + \
+                         [f"{name}_pos" for name in joint_names] + \
+                         [f"{name}_target_pos" for name in joint_names] + \
+                         [f"{name}_vel" for name in joint_names]
             writer = csv.DictWriter(log_file, fieldnames=fieldnames)
             writer.writeheader()
             joint_writers.append(writer)
@@ -239,6 +253,31 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
         start_time = time.time()
         # run everything in inference mode
         with torch.inference_mode():
+            # # === [추가 2] 키보드 명령 주입 ===
+            # # 1. 키보드 입력 받기 (delta 값 수신)
+            # delta_pose = teleop_interface.advance()
+            # delta_vel = delta_pose[0:3]
+            # delta_ang_vel = delta_pose[3:6]
+            
+            # # 2. 입력값이 있을 때만 명령 업데이트 (없으면 0 또는 이전 값 유지 등 정책에 따라 다름)
+            # # 여기서는 매 스텝 키 입력을 반영하도록 작성합니다.
+            
+            # # 환경의 로봇 개수 확인
+            # num_envs = env.unwrapped.scene.num_envs
+            # device = env.unwrapped.device
+            
+            # # 3. 커맨드 텐서 생성 (모든 환경에 동일한 명령 적용)
+            # cmd_tensor = torch.zeros(num_envs, 3, device=device)
+            # cmd_tensor[:, 0] = delta_vel[0] # Forward/Back (W/S)
+            # cmd_tensor[:, 1] = delta_vel[1] # Left/Right (A/D)
+            # cmd_tensor[:, 2] = delta_ang_vel[2] # Yaw Turn (Q/E)
+            
+            # # 4. Command Manager에 강제 주입
+            # # 주의: env가 Wrapper로 감싸져 있으므로 .unwrapped를 통해 접근해야 합니다.
+            # # "base_velocity"는 config에서 정의한 이름과 일치해야 합니다.
+            # if hasattr(env.unwrapped, "command_manager"):
+            #     env.unwrapped.command_manager.get_command("base_velocity")[:] = cmd_tensor
+            # # ================================
             # agent stepping
             actions = policy(obs)
             # env stepping
@@ -251,6 +290,23 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
             joint_vel = robot.data.joint_vel.cpu().numpy()  # Shape: [num_envs, num_joints]
             current_time = timestep * dt
             
+            # Calculate target positions for all environments
+            # target = default + action * scale
+            try:
+                default_pos = robot.data.default_joint_pos.cpu().numpy() # Shape: [num_envs, num_joints]
+                # Get action scale (assuming uniform scale for now, or try to fetch from config)
+                action_scale = 1.0
+                if hasattr(env.unwrapped, "action_manager"):
+                     term = env.unwrapped.action_manager._terms.get("joint_pos")
+                     if term and hasattr(term.cfg, "scale"):
+                         action_scale = term.cfg.scale
+                
+                # actions shape: [num_envs, num_actions]
+                actions_np = actions.cpu().numpy()
+                target_pos_all = default_pos + actions_np * action_scale
+            except Exception:
+                target_pos_all = np.zeros_like(joint_pos)
+
             # Log data for each environment
             for env_idx in range(env.unwrapped.scene.num_envs):
                 row_data = {
@@ -258,9 +314,10 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
                     'time': current_time
                 }
                 
-                # Add joint positions
+                # Add joint positions, targets, and velocities
                 for joint_idx, joint_name in enumerate(robot.data.joint_names):
                     row_data[f"{joint_name}_pos"] = joint_pos[env_idx, joint_idx]
+                    row_data[f"{joint_name}_target_pos"] = target_pos_all[env_idx, joint_idx]
                     row_data[f"{joint_name}_vel"] = joint_vel[env_idx, joint_idx]
                 
                 joint_writers[env_idx].writerow(row_data)
diff --git a/source/isaaclab/isaaclab/envs/mdp/observations.py b/source/isaaclab/isaaclab/envs/mdp/observations.py
index ac502521aa..05dc9b286b 100644
--- a/source/isaaclab/isaaclab/envs/mdp/observations.py
+++ b/source/isaaclab/isaaclab/envs/mdp/observations.py
@@ -285,7 +285,6 @@ def joint_effort(env: ManagerBasedEnv, asset_cfg: SceneEntityCfg = SceneEntityCf
 Sensors.
 """
 
-
 def height_scan(env: ManagerBasedEnv, sensor_cfg: SceneEntityCfg, offset: float = 0.5) -> torch.Tensor:
     """Height scan from the given sensor w.r.t. the sensor's frame.
 
@@ -296,6 +295,16 @@ def height_scan(env: ManagerBasedEnv, sensor_cfg: SceneEntityCfg, offset: float
     # height scan: height = sensor_height - hit_point_z - offset
     return sensor.data.pos_w[:, 2].unsqueeze(1) - sensor.data.ray_hits_w[..., 2] - offset
 
+def lidar_scan(env: ManagerBasedEnv, sensor_cfg: SceneEntityCfg) -> torch.Tensor:
+    """Lidar scan from the given sensor.
+
+    Returns the distance from the sensor origin to the hit point.
+    """
+    # extract the used quantities (to enable type-hinting)
+    sensor: RayCaster = env.scene.sensors[sensor_cfg.name]
+    # lidar scan: distance = norm(hit_point - sensor_pos)
+    return torch.norm(sensor.data.ray_hits_w - sensor.data.pos_w.unsqueeze(1), dim=-1)
+
 
 def body_incoming_wrench(env: ManagerBasedEnv, asset_cfg: SceneEntityCfg) -> torch.Tensor:
     """Incoming spatial wrench on bodies of an articulation in the simulation world frame.
diff --git a/source/isaaclab/isaaclab/terrains/config/rough.py b/source/isaaclab/isaaclab/terrains/config/rough.py
index 3b2a16f7ab..6713070b1a 100644
--- a/source/isaaclab/isaaclab/terrains/config/rough.py
+++ b/source/isaaclab/isaaclab/terrains/config/rough.py
@@ -12,6 +12,7 @@ from ..terrain_generator_cfg import TerrainGeneratorCfg
 ROUGH_TERRAINS_CFG = TerrainGeneratorCfg(
     size=(8.0, 8.0),
     border_width=20.0,
+    border_height=0.1, # Wall height (negative value for wall above ground)
     num_rows=10,
     num_cols=20,
     horizontal_scale=0.1,
@@ -50,3 +51,40 @@ ROUGH_TERRAINS_CFG = TerrainGeneratorCfg(
     },
 )
 """Rough terrains configuration."""
+
+STAIR_TERRAINS_CFG = TerrainGeneratorCfg(
+    size=(8.0, 8.0),
+    border_width=20.0,
+    border_height=0.1, # Wall height (negative value for wall above ground)
+    num_rows=10,
+    num_cols=20,
+    horizontal_scale=0.1,
+    vertical_scale=0.005,
+    slope_threshold=0.75,
+    use_cache=False,
+    sub_terrains={
+        "pyramid_stairs": terrain_gen.MeshPyramidStairsTerrainCfg(
+            proportion=0.2,
+            step_height_range=(0.05, 0.23),
+            step_width=0.3,
+            platform_width=3.0,
+            border_width=1.0,
+            holes=False,
+        ),
+        "pyramid_stairs_inv": terrain_gen.MeshInvertedPyramidStairsTerrainCfg(
+            proportion=0.2,
+            step_height_range=(0.05, 0.23),
+            step_width=0.3,
+            platform_width=3.0,
+            border_width=1.0,
+            holes=False,
+        ),
+        "hf_pyramid_slope": terrain_gen.HfPyramidSlopedTerrainCfg(
+            proportion=0.1, slope_range=(0.0, 0.4), platform_width=2.0, border_width=0.25
+        ),
+        "hf_pyramid_slope_inv": terrain_gen.HfInvertedPyramidSlopedTerrainCfg(
+            proportion=0.1, slope_range=(0.0, 0.4), platform_width=2.0, border_width=0.25
+        ),
+    },
+)
+"""Stair terrains configuration."""
\ No newline at end of file
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/agents/rsl_rl_ppo_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/agents/rsl_rl_ppo_cfg.py
index db4e77c9e3..a22695b1f4 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/agents/rsl_rl_ppo_cfg.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/agents/rsl_rl_ppo_cfg.py
@@ -15,8 +15,8 @@ class UnitreeGo2RoughPPORunnerCfg(RslRlOnPolicyRunnerCfg):
     save_interval = 50
     experiment_name = "unitree_go2_rough"
     policy = RslRlPpoActorCriticCfg(
-        init_noise_std=0.8,
-        noise_std_type="log",
+        init_noise_std=1.0,
+        #noise_std_type="log",
         actor_obs_normalization=False,
         critic_obs_normalization=False,
         actor_hidden_dims=[512, 256, 128],
@@ -30,7 +30,7 @@ class UnitreeGo2RoughPPORunnerCfg(RslRlOnPolicyRunnerCfg):
         entropy_coef=0.01,
         num_learning_epochs=5,
         num_mini_batches=4,
-        learning_rate=5.0e-5,
+        learning_rate=1.0e-3,
         schedule="adaptive",
         gamma=0.99,
         lam=0.95,
@@ -57,7 +57,7 @@ class UnitreeGo2StairPPORunnerCfg(RslRlOnPolicyRunnerCfg):
     save_interval = 50
     experiment_name = "unitree_go2_stair"
     policy = RslRlPpoActorCriticCfg(
-        init_noise_std=0.8,
+        init_noise_std=1.0,
         noise_std_type="log",
         actor_obs_normalization=True,
         critic_obs_normalization=True,
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/rough_env_cfg_pdgain_fix.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/rough_env_cfg_pdgain_fix.py
index 77f6b43138..e1f16ca1e8 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/rough_env_cfg_pdgain_fix.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/copy_dir/rough_env_cfg_pdgain_fix.py
@@ -51,25 +51,27 @@ class UnitreeGo2RoughEnvCfg(LocomotionVelocityRoughEnvCfg):
         # Action configuration - optimized for Go2
         self.actions.joint_pos.scale = 0.25  # Reduced for better stability
 
-        # ============ REWARD CONFIGURATION (legged-loco style) ============
+        # ============ REWARD CONFIGURATION (Total Rewards: 2.5, Total Penalties: -2.5) ============
         # Core locomotion rewards
-        # Linear Velocity Tracking - 전체 가중치 5 미만으로 조정
-        self.rewards.track_lin_vel_xy_exp.weight = 3.0  # 주요 보상
-        self.rewards.track_ang_vel_z_exp.weight = 0.6   # 각속도 추적 보상
+        # Linear Velocity Tracking
+        self.rewards.track_lin_vel_xy_exp.weight = 1.5  # 주요 보상
+        self.rewards.track_ang_vel_z_exp.weight = 0.5   # 각속도 추적 보상
         # Body stability  
         self.rewards.flat_orientation_l2.weight = -1.0  # 자세 페널티
-        self.rewards.lin_vel_z_l2.weight = -0.4        # 수직 속도 페널티
-        self.rewards.ang_vel_xy_l2.weight = -0.02      # 각속도 페널티
+        self.rewards.lin_vel_z_l2.weight = -0.5         # 수직 속도 페널티
+        self.rewards.ang_vel_xy_l2.weight = -0.05       # 각속도 페널티
         # Joint and action penalties
-        self.rewards.dof_torques_l2.weight = -0.0001  # 토크 페널티
-        self.rewards.dof_acc_l2.weight = -1.0e-7      # 가속도 페널티
-        self.rewards.action_rate_l2.weight = -0.01    # 액션 변화율 페널티
+        self.rewards.dof_torques_l2.weight = -0.05      # 토크 페널티
+        self.rewards.dof_acc_l2.weight = -2.5e-4        # 가속도 페널티
+        self.rewards.dof_pos_limits.weight = -2.5e-4    # 관절 위치 한계 페널티
+        self.rewards.action_rate_l2.weight = -0.05      # 액션 변화율 페널티
+
         # Foot contact rewards
         self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
-        self.rewards.feet_air_time.weight = 0.15  # 발 접촉 보상
+        self.rewards.feet_air_time.weight = 0.5         # 발 접촉 보상 
         # Fix unwanted contacts body name pattern and disable for better terrain adaptation
-        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh"
-        self.rewards.undesired_contacts.weight = -0.0001  # 약한 페널티로 조정
+        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh|.*_hip|Head_lower"
+        self.rewards.undesired_contacts.weight = -0.4   # 접촉 페널티
         
 
         # ============ EVENT CONFIGURATION ============
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
index 529b5457ad..2d6621cd81 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/rough_env_cfg.py
@@ -15,91 +15,107 @@ from isaaclab_assets.robots.unitree import UNITREE_GO2_CFG  # isort: skip
 
 @configclass
 class UnitreeGo2RoughEnvCfg(LocomotionVelocityRoughEnvCfg):
-    """Configuration for Go2 rough terrain locomotion with legged-loco training patterns."""
-    
     def __post_init__(self):
         # post init of parent
         super().__post_init__()
-        
-        # Go2 robot configuration with legged-loco training patterns
 
-        # Robot configuration
+        # ============ ROBOT CONFIGURATION ============
+        # Go2 robot configuration with legged-loco training patterns
         from copy import deepcopy
-        from isaaclab.actuators import DCMotorCfg
         self.scene.robot = deepcopy(UNITREE_GO2_CFG)
         self.scene.robot.prim_path = "{ENV_REGEX_NS}/Robot"
         self.scene.height_scanner.prim_path = "{ENV_REGEX_NS}/Robot/base"
-        self.scene.height_scanner.debug_vis = False
-        
-        # # Actuator configuration with custom stiffness and damping
-        # self.scene.robot.actuators["base_legs"] = DCMotorCfg(
-        #     joint_names_expr=[".*_hip_joint", ".*_thigh_joint", ".*_calf_joint"],
-        #     effort_limit=23.5,
-        #     saturation_effort=23.5,
-        #     velocity_limit=30.0,
-        #     stiffness=25.0,  # Increased from default 25.0 
-        #     damping=0.5,     # Increased from default 0.5
-        #     friction=0.0,
-        # )
-        
-        # Simulation settings
-        self.decimation = 4
-        self.sim.render_interval = 4
-        self.episode_length_s = 20.0
-        self.sim.dt = 0.005
-        
-        # Action configuration - optimized for Go2
-        self.actions.joint_pos.scale = 0.25  # Reduced for better stability
-
-        # ============ REWARD CONFIGURATION (legged-loco style) ============
-        # Core locomotion rewards
-        # Linear Velocity Tracking - 전체 가중치 5 미만으로 조정
-        self.rewards.track_lin_vel_xy_exp.weight = 3.0  # 주요 보상
-        self.rewards.track_ang_vel_z_exp.weight = 0.6   # 각속도 추적 보상
-        # Body stability  
-        self.rewards.flat_orientation_l2.weight = -1.0  # 자세 페널티
-        self.rewards.lin_vel_z_l2.weight = -0.4        # 수직 속도 페널티
-        self.rewards.ang_vel_xy_l2.weight = -0.02      # 각속도 페널티
-        # Joint and action penalties
-        self.rewards.dof_torques_l2.weight = -0.0001  # 토크 페널티
-        self.rewards.dof_acc_l2.weight = -1.0e-7      # 가속도 페널티
-        self.rewards.action_rate_l2.weight = -0.01    # 액션 변화율 페널티
-        # Foot contact rewards
-        self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
-        self.rewards.feet_air_time.weight = 0.15  # 발 접촉 보상
-        # Fix unwanted contacts body name pattern and disable for better terrain adaptation
-        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh"        
+
+        # ============ TERRAIN CONFIGURATION ============
+        # scale down the terrains because the robot is small
+        self.scene.terrain.terrain_generator.sub_terrains["boxes"].grid_height_range = (0.025, 0.1)
+        self.scene.terrain.terrain_generator.sub_terrains["random_rough"].noise_range = (0.01, 0.06)
+        self.scene.terrain.terrain_generator.sub_terrains["random_rough"].noise_step = 0.01
+
+        # ============ ACTION CONFIGURATION ============
+        # reduce action scale
+        self.actions.joint_pos.scale = 0.25
+
+        # [추가] 액션 클리핑: 목표 관절 위치가 물리적 한계를 넘지 않도록 강제 제한 (안전 장치)
+        # 값은 라디안 단위이며, 필요에 따라 로봇의 실제 관절 한계값으로 더 좁게 설정 가능
+        self.actions.joint_pos.clip = {
+            ".*_hip_joint": (-0.84, 0.84),        # 좌우 벌림 제한
+            ".*_thigh_joint": (-4.0, 1.5),        # 앞뒤 허벅지 (앞/뒤 다리 통합하여 넓게 잡음)
+            ".*_calf_joint": (-2.72, -0.84),      # 종아리 (무릎 굽힘 제한)
+        }
+
+        # ============ COMMAND CONFIGURATION ============
+        # Velocity command ranges optimized for Go2
+        self.commands.base_velocity.ranges.lin_vel_x = (-1.0, 1.0)
+        self.commands.base_velocity.ranges.lin_vel_y = (-0.5, 0.5)
+        self.commands.base_velocity.ranges.ang_vel_z = (-1.0, 1.0)
+        self.commands.base_velocity.rel_standing_envs = 0.1
 
         # ============ EVENT CONFIGURATION ============
-        # Mass randomization
-        self.events.add_base_mass.params["mass_distribution_params"] = (-3.0, 3.0)
+        self.events.base_com = None
+        self.events.add_base_mass.params["mass_distribution_params"] = (-5.0, 5.0)
         self.events.add_base_mass.params["asset_cfg"].body_names = "base"
         self.events.base_external_force_torque.params["asset_cfg"].body_names = "base"
-        
-        # Joint initialization
         self.events.reset_robot_joints.params["position_range"] = (1.0, 1.0)
         self.events.reset_base.params = {
             "pose_range": {"x": (-0.5, 0.5), "y": (-0.5, 0.5), "yaw": (-3.14, 3.14)},
             "velocity_range": {
-                "x": (0.0, 0.0), "y": (0.0, 0.0), "z": (0.0, 0.0),
-                "roll": (0.0, 0.0), "pitch": (0.0, 0.0), "yaw": (0.0, 0.0),
+                "x": (0.0, 0.0),
+                "y": (0.0, 0.0),
+                "z": (0.0, 0.0),
+                "roll": (0.0, 0.0),
+                "pitch": (0.0, 0.0),
+                "yaw": (0.0, 0.0),
             },
         }
-        
-        # ============ COMMAND CONFIGURATION ============
-        # Velocity command ranges optimized for Go2
-        self.commands.base_velocity.ranges.lin_vel_x = (-1.0, 1.0)
-        self.commands.base_velocity.ranges.lin_vel_y = (-0.5, 0.5)
-        self.commands.base_velocity.ranges.ang_vel_z = (-1.0, 1.0)
-        self.commands.base_velocity.rel_standing_envs = 0.1
-        
+
+        # ============ REWARD CONFIGURATION (Total Rewards: 2.5, Total Penalties: -2.5) ============
+        self.rewards.track_lin_vel_xy_exp.weight = 1.5
+        self.rewards.track_ang_vel_z_exp.weight = 0.5
+        self.rewards.feet_air_time.weight = 0.5
+        self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
+
+        self.rewards.lin_vel_z_l2.weight = -1.0
+        self.rewards.flat_orientation_l2.weight = -0.8
+        self.rewards.action_rate_l2.weight = -0.1
+        self.rewards.stand_still_joint_deviation_l1.weight = -0.1
+        self.rewards.ang_vel_xy_l2.weight = -0.05
+
+        self.rewards.dof_torques_l2.weight = -0.0002
+        self.rewards.dof_acc_l2.weight = -2.5e-7
+
+        self.rewards.undesired_contacts.weight = -0.45
+        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh|.*_hip|Head_lower"
+
+        # # Core locomotion rewards
+        # # Linear Velocity Tracking
+        # self.rewards.track_lin_vel_xy_exp.weight = 1.5  # 주요 보상
+        # self.rewards.track_ang_vel_z_exp.weight = 0.5   # 각속도 추적 보상
+        # # Body stability  
+        # self.rewards.flat_orientation_l2.weight = -1.0  # 자세 페널티
+        # self.rewards.lin_vel_z_l2.weight = -0.5         # 수직 속도 페널티
+        # self.rewards.ang_vel_xy_l2.weight = -0.05       # 각속도 페널티
+        # # Joint and action penalties
+        # self.rewards.dof_torques_l2.weight = -0.0005    # 토크 페널티
+        # self.rewards.dof_acc_l2.weight = -6.25e-7       # 가속도 페널티
+        # self.rewards.dof_pos_limits.weight = -6.25e-7   # 관절 위치 한계 페널티
+        # self.rewards.action_rate_l2.weight = -0.1       # 액션 변화율 페널티
+
+        # # Foot contact rewards
+        # self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
+        # self.rewards.feet_air_time.weight = 0.5         # 발 접촉 보상 
+        # # Fix unwanted contacts body name pattern and disable for better terrain adaptation
+        # self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh|.*_hip|Head_lower"
+        # self.rewards.undesired_contacts.weight = -0.4   # 접촉 페널티
+
         # ============ TERMINATION CONFIGURATION ============
         self.terminations.base_contact.params["sensor_cfg"].body_names = "base"
-        
+
+        # ============ SENSOR CONFIGURATION ============
         # Update sensor periods
         self.scene.contact_forces.update_period = self.sim.dt
         self.scene.height_scanner.update_period = self.sim.dt * self.decimation
-
+        # self.scene.lidar_scanner.update_period = self.sim.dt * self.decimation
 
 @configclass
 class UnitreeGo2RoughEnvCfg_PLAY(UnitreeGo2RoughEnvCfg):
@@ -125,4 +141,8 @@ class UnitreeGo2RoughEnvCfg_PLAY(UnitreeGo2RoughEnvCfg):
         
         # remove random pushing event
         self.events.base_external_force_torque = None
-        self.events.push_robot = None
\ No newline at end of file
+        self.events.push_robot = None
+
+        # # [권장] 랜덤 명령어가 자동으로 바뀌지 않게 설정 (무한대 시간 설정)
+        # self.commands.base_velocity.resampling_time_range = (1.0e9, 1.0e9) 
+        # self.commands.base_velocity.debug_vis = True # 화살표로 명령 방향 보기
\ No newline at end of file
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/stair_env_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/stair_env_cfg.py
index 29abf90b28..60a89ed1eb 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/stair_env_cfg.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/go2/stair_env_cfg.py
@@ -21,60 +21,35 @@ class UnitreeGo2StairEnvCfg(LocomotionVelocityRoughEnvCfg):
         # post init of parent
         super().__post_init__()
         
-        # Go2 robot configuration with legged-loco training patterns
+        # ============ TERRAIN CONFIGURATION ============
+        # Stair Terrain configuration
+        from isaaclab.terrains.config.rough import STAIR_TERRAINS_CFG  # isort: skip
+        self.scene.terrain.terrain_generator = STAIR_TERRAINS_CFG
+        # self.scene.terrain.max_init_terrain_level = 0 # default 5
+        # self.scene.terrain.terrain_generator.curriculum = False
 
-        # Robot configuration
+        # ============ ROBOT CONFIGURATION ============
+        # Go2 robot configuration with legged-loco training patterns
         from copy import deepcopy
-        from isaaclab.actuators import DCMotorCfg
         self.scene.robot = deepcopy(UNITREE_GO2_CFG)
         self.scene.robot.prim_path = "{ENV_REGEX_NS}/Robot"
         self.scene.height_scanner.prim_path = "{ENV_REGEX_NS}/Robot/base"
         self.scene.height_scanner.debug_vis = False
         
-        # Actuator configuration with custom stiffness and damping
-        self.scene.robot.actuators["base_legs"] = DCMotorCfg(
-            joint_names_expr=[".*_hip_joint", ".*_thigh_joint", ".*_calf_joint"],
-            effort_limit=23.5,
-            saturation_effort=23.5,
-            velocity_limit=30.0,
-            stiffness=25.0,  # Increased from default 25.0 
-            damping=0.5,     # Increased from default 0.5
-            friction=0.0,
-        )
-        
-        # Simulation settings
-        self.decimation = 4
-        self.sim.render_interval = 4
-        self.episode_length_s = 20.0
-        self.sim.dt = 0.005
-        
+        # ============ ACTION CONFIGURATION ============
         # Action configuration - optimized for Go2
-        self.actions.joint_pos.scale = 0.25  # Reduced for better stability
-
-        # ============ REWARD CONFIGURATION (legged-loco style) ============
-        # Core locomotion rewards
-        # Linear Velocity Tracking - 전체 가중치 5 미만으로 조정
-        self.rewards.track_lin_vel_xy_exp.weight = 3.0  # 주요 보상
-        self.rewards.track_ang_vel_z_exp.weight = 0.6   # 각속도 추적 보상
-        # Body stability  
-        self.rewards.flat_orientation_l2.weight = -1.0  # 자세 페널티
-        self.rewards.lin_vel_z_l2.weight = -0.4        # 수직 속도 페널티
-        self.rewards.ang_vel_xy_l2.weight = -0.02      # 각속도 페널티
-        # Joint and action penalties
-        self.rewards.dof_torques_l2.weight = -0.0001  # 토크 페널티
-        self.rewards.dof_acc_l2.weight = -1.0e-7      # 가속도 페널티
-        self.rewards.action_rate_l2.weight = -0.01    # 액션 변화율 페널티
-        # Foot contact rewards
-        self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
-        self.rewards.feet_air_time.weight = 0.15  # 발 접촉 보상
-        # Fix unwanted contacts body name pattern and disable for better terrain adaptation
-        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh"
-        self.rewards.undesired_contacts.weight = -0.01  # 약한 페널티로 조정
-        
+        self.actions.joint_pos.scale = 0.25  # Default is 0.25
+
+        self.actions.joint_pos.clip = {
+            ".*_hip_joint": (-0.84, 0.84),        # 좌우 벌림 제한
+            ".*_thigh_joint": (-4.0, 1.5),        # 앞뒤 허벅지 (앞/뒤 다리 통합하여 넓게 잡음)
+            ".*_calf_joint": (-2.72, -0.84),      # 종아리 (무릎 굽힘 제한)
+        }
 
         # ============ EVENT CONFIGURATION ============
         # Mass randomization
-        self.events.add_base_mass.params["mass_distribution_params"] = (-3.0, 3.0)
+        self.events.physics_material.params["num_buckets"] = 1
+        self.events.add_base_mass.params["mass_distribution_params"] = (-5.0, 5.0)
         self.events.add_base_mass.params["asset_cfg"].body_names = "base"
         self.events.base_external_force_torque.params["asset_cfg"].body_names = "base"
         
@@ -87,20 +62,56 @@ class UnitreeGo2StairEnvCfg(LocomotionVelocityRoughEnvCfg):
                 "roll": (0.0, 0.0), "pitch": (0.0, 0.0), "yaw": (0.0, 0.0),
             },
         }
+
+        # ============ REWARD CONFIGURATION (Total Rewards: 2.5, Total Penalties: -2.5) ============
+        self.rewards.flat_orientation_l2.weight = -1.0 
+        self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
+        self.rewards.feet_air_time.weight = 0.5
+        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh|.*_hip|Head_lower"
+        self.rewards.undesired_contacts.weight = -0.1
+        self.rewards.track_lin_vel_xy_exp.weight = 1.5
+        self.rewards.track_ang_vel_z_exp.weight = 0.5
+        self.rewards.dof_torques_l2.weight = -0.0002
+        self.rewards.dof_acc_l2.weight = -2.5e-7
+        self.rewards.lin_vel_z_l2.weight = -2.0
+        self.rewards.action_rate_l2.weight = -0.01
+
+        # # Core locomotion rewards
+        # # Linear Velocity Tracking
+        # self.rewards.track_lin_vel_xy_exp.weight = 1.5  # 주요 보상 
+        # self.rewards.track_ang_vel_z_exp.weight = 0.5   # 각속도 추적 보상 
+        # # Body stability  
+        # self.rewards.flat_orientation_l2.weight = -1.0  # 자세 페널티
+        # self.rewards.lin_vel_z_l2.weight = -0.5         # 수직 속도 페널티
+        # self.rewards.ang_vel_xy_l2.weight = -0.05       # 각속도 페널티
+        # # Joint and action penalties
+        # self.rewards.dof_torques_l2.weight = -0.0005    # 토크 페널티
+        # self.rewards.dof_acc_l2.weight = -6.25e-7       # 가속도 페널티
+        # self.rewards.dof_pos_limits.weight = -6.25e-7   # 관절 위치 한계 페널티
+        # self.rewards.action_rate_l2.weight = -0.1       # 액션 변화율 페널티
+
+        # # Foot contact rewards
+        # self.rewards.feet_air_time.params["sensor_cfg"].body_names = ".*_foot"
+        # self.rewards.feet_air_time.weight = 0.5         # 발 접촉 보상
+        # # Fix unwanted contacts body name pattern and disable for better terrain adaptation
+        # self.rewards.undesired_contacts.params["sensor_cfg"].body_names = ".*_thigh|.*_hip|Head_lower"
+        # self.rewards.undesired_contacts.weight = -0.4   # 접촉 페널티
         
-        # ============ COMMAND CONFIGURATION ============
-        # Velocity command ranges optimized for Go2
-        self.commands.base_velocity.ranges.lin_vel_x = (-1.0, 1.0)
-        self.commands.base_velocity.ranges.lin_vel_y = (-0.5, 0.5)
-        self.commands.base_velocity.ranges.ang_vel_z = (-1.0, 1.0)
-        self.commands.base_velocity.rel_standing_envs = 0.1
+        
+        # # ============ COMMAND CONFIGURATION ============
+        # # Velocity command ranges optimized for Go2
+        # self.commands.base_velocity.ranges.lin_vel_x = (-1.0, 1.0)
+        # self.commands.base_velocity.ranges.lin_vel_y = (-0.5, 0.5)
+        # self.commands.base_velocity.ranges.ang_vel_z = (-1.0, 1.0)
+        # self.commands.base_velocity.rel_standing_envs = 0.1
         
         # ============ TERMINATION CONFIGURATION ============
         self.terminations.base_contact.params["sensor_cfg"].body_names = "base"
-        
+
         # Update sensor periods
         self.scene.contact_forces.update_period = self.sim.dt
         self.scene.height_scanner.update_period = self.sim.dt * self.decimation
+        #self.scene.lidar_scanner.update_period = self.sim.dt * self.decimation
 
 
 @configclass
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
index 4be16c1368..80d0bd67b8 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
@@ -63,7 +63,9 @@ class MySceneCfg(InteractiveSceneCfg):
     )
     # robots
     robot: ArticulationCfg = MISSING
+    
     # sensors
+    # height scanner = None
     height_scanner = RayCasterCfg(
         prim_path="{ENV_REGEX_NS}/Robot/base",
         offset=RayCasterCfg.OffsetCfg(pos=(0.0, 0.0, 20.0)),
@@ -72,8 +74,28 @@ class MySceneCfg(InteractiveSceneCfg):
         debug_vis=False,
         mesh_prim_paths=["/World/ground"],
     )
+    # lidar_scanner = None
+    # lidar_scanner = RayCasterCfg(
+    #     prim_path="{ENV_REGEX_NS}/Robot/Head_lower",
+    #     offset=RayCasterCfg.OffsetCfg(pos=(0, 0, 0.5)),
+    #     ray_alignment="yaw",
+    #     pattern_cfg=patterns.LidarPatternCfg(
+    #         channels=8,
+    #         vertical_fov_range=[-45.0, 45.0], 
+    #         horizontal_fov_range=[-180.0, 180.0], 
+    #         horizontal_res=1.0
+    #     ),
+    #     max_distance=1.0,
+    #     debug_vis=False,
+    #     mesh_prim_paths=["/World/ground"],
+    # )
+    # contact forces = None
+    contact_forces = ContactSensorCfg(
+        prim_path="{ENV_REGEX_NS}/Robot/.*",
+        history_length=3, 
+        track_air_time=True
+    )
     
-    contact_forces = ContactSensorCfg(prim_path="{ENV_REGEX_NS}/Robot/.*", history_length=3, track_air_time=True)
     # lights
     sky_light = AssetBaseCfg(
         prim_path="/World/skyLight",
@@ -100,7 +122,10 @@ class CommandsCfg:
         heading_control_stiffness=0.5,
         debug_vis=True,
         ranges=mdp.UniformVelocityCommandCfg.Ranges(
-            lin_vel_x=(-1.0, 1.0), lin_vel_y=(-1.0, 1.0), ang_vel_z=(-1.0, 1.0), heading=(-math.pi, math.pi)
+            lin_vel_x=(-1.0, 1.0),
+            lin_vel_y=(-1.0, 1.0),
+            ang_vel_z=(-1.0, 1.0),
+            heading=(-math.pi, math.pi)
         ),
     )
 
@@ -133,6 +158,12 @@ class ObservationsCfg:
             noise=Unoise(n_min=-0.1, n_max=0.1),
             clip=(-1.0, 1.0),
         )
+        # lidar_scan = ObsTerm(
+        #     func=mdp.lidar_scan,
+        #     params={"sensor_cfg": SceneEntityCfg("lidar_scanner")},
+        #     noise=Unoise(n_min=-0.1, n_max=0.1),
+        #     clip=(-1.0, 1.0),
+        # )
         def __post_init__(self):
             self.enable_corruption = True
             self.concatenate_terms = True
@@ -218,10 +249,14 @@ class RewardsCfg:
     """Reward terms for the MDP."""
     # -- task
     track_lin_vel_xy_exp = RewTerm(
-        func=mdp.track_lin_vel_xy_exp, weight=1.0, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
+        func=mdp.track_lin_vel_xy_exp,
+        weight=1.0,
+        params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
     )
     track_ang_vel_z_exp = RewTerm(
-        func=mdp.track_ang_vel_z_exp, weight=0.5, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
+        func=mdp.track_ang_vel_z_exp, 
+        weight=0.5, 
+        params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
     )
     # -- penalties
     lin_vel_z_l2 = RewTerm(func=mdp.lin_vel_z_l2, weight=-2.0)
@@ -246,15 +281,14 @@ class RewardsCfg:
     # -- optional penalties
     flat_orientation_l2 = RewTerm(func=mdp.flat_orientation_l2, weight=0.0)
     dof_pos_limits = RewTerm(func=mdp.joint_pos_limits, weight=0.0)
-    base_height = RewTerm(
-        func=mdp.base_height_l2,
+    stand_still_joint_deviation_l1 = RewTerm(
+        func=mdp.stand_still_joint_deviation_l1,
+        weight=0.0,
         params={
-            "sensor_cfg": SceneEntityCfg("height_scanner"),
-            "target_height": 0.32,
+            "command_name": "base_velocity", 
         },
-        weight=-0.5
     )
-
+    
 @configclass
 class TerminationsCfg:
     """Termination terms for the MDP."""
@@ -308,12 +342,15 @@ class LocomotionVelocityRoughEnvCfg(ManagerBasedRLEnvCfg):
         self.sim.render_interval = self.decimation
         self.sim.physics_material = self.scene.terrain.physics_material
         self.sim.physx.gpu_max_rigid_patch_count = 10 * 2**15
+        
         # update sensor update periods
         # we tick all the sensors based on the smallest update period (physics update period)
         if self.scene.height_scanner is not None:
             self.scene.height_scanner.update_period = self.decimation * self.sim.dt
         if self.scene.contact_forces is not None:
             self.scene.contact_forces.update_period = self.sim.dt
+        # if self.scene.lidar_scanner is not None:
+        #     self.scene.lidar_scanner.update_period = self.decimation * self.sim.dt
 
         # check if terrain levels curriculum is enabled - if so, enable curriculum for terrain generator
         # this generates terrains with increasing difficulty and is useful for training
diff --git a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg_default.py b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg_default.py
index 519cd07c22..9350272efb 100644
--- a/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg_default.py
+++ b/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/velocity_env_cfg_default.py
@@ -233,10 +233,14 @@ class RewardsCfg:
 
     # -- task
     track_lin_vel_xy_exp = RewTerm(
-        func=mdp.track_lin_vel_xy_exp, weight=1.0, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
+        func=mdp.track_lin_vel_xy_exp, 
+        weight=1.0, 
+        params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
     )
     track_ang_vel_z_exp = RewTerm(
-        func=mdp.track_ang_vel_z_exp, weight=0.5, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
+        func=mdp.track_ang_vel_z_exp, 
+        weight=0.5, 
+        params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
     )
     # -- penalties
     lin_vel_z_l2 = RewTerm(func=mdp.lin_vel_z_l2, weight=-2.0)