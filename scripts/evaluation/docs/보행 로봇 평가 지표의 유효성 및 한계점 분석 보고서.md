# **보행 로봇 평가 지표의 유효성 및 한계점 분석 보고서 (Final Comprehensive Report)**

## **1. 서론: 수치는 거짓말을 하지 않지만, 해석은 틀릴 수 있다**

강화학습(RL) 모델의 성능을 평가할 때, 우리는 종종 **Cost of Transport (CoT)** 나 **RMSE** 같은 숫자에 매몰되기 쉽습니다. 그러나 "CoT가 0.5다"라는 사실이 곧 "로봇이 잘 걷는다"를 의미하지는 않습니다. 로봇이 제자리에서 꼼짝하지 않아도, 혹은 미끄러운 바닥에서 헛바퀴를 돌고 있어도 수치는 좋게 나올 수 있기 때문입니다.

본 보고서는 `Isaac Lab Evaluation Pipeline`의 비판적 분석 결과를 바탕으로, 각 지표가 가진 **태생적 한계(Limitations)**와 이를 극복하고 **유효성(Validity)**을 확보하기 위해 적용된 기술적 장치들을 정리합니다.

---

## **2. 데이터 무결성: 평가의 전제 조건 (Prerequisites)**

지표를 논하기 전에, 그 지표를 계산하는 **데이터의 품질**이 보장되어야 합니다. 본 프로젝트는 다음 두 가지 기술을 통해 "오염된 데이터"를 배제합니다.

1.  **Smart Logging (지능형 로깅):**
    *   **문제:** 로봇이 대기 중이거나 넘어져서 버둥거리는 데이터가 포함되면 평균 속도가 0에 수렴하여 CoT가 무한대로 발산합니다.
    *   **해결:** `logger_node.py`에 구현된 버퍼링 시스템은 유의미한 움직임(Cmd > 0.01)이 있을 때만 데이터를 기록하며, 전후 0.5초를 포함하여 맥락을 보존합니다.

2.  **Robust State Estimation (강건한 상태 추정):**
    *   **문제:** 실내외 험지에서는 발이 미끄러지거나(Slip) 붕 뜨는 현상이 빈번하여, 단순 엔코더 값으로는 속도를 알 수 없습니다.
    *   **해결:** `state_estimate.py`는 **Torque-based Contact Detection**과 **IMU Fusion**을 결합하여, 센서가 속는 상황에서도 실제 속도에 근접한 추정치를 제공합니다.

---

## **3. 지표별 심층 분석 (Deep Dive)**

### **3.1. Cost of Transport (CoT, 운송 비용)**
*   **판단:** **"조건부 유효 (Conditionally Valid)"** - *가장 오해하기 쉬운 지표*
*   **공식:** $CoT = \frac{P}{mgv}$
*   **치명적 한계 (The Trap):**
    *   분모에 속도($v$)가 있습니다. 로봇이 장애물에 걸려 멈추면($v \to 0$), 에너지를 적게 써도 CoT는 폭등합니다.
    *   반대로, 빙판에서 헛돌면($v$ 과대평가), 에너지를 많이 써도 CoT는 낮게(좋게) 나옵니다.
*   **올바른 활용법:**
    *   단순 평균이 아닌, **Speed Filtering (> 0.2 m/s)**을 통과한 구간의 데이터만 신뢰해야 합니다.
    *   **Mech CoT**(모터 효율)와 **Elec CoT**(전체 시스템 효율)를 구분하여, 알고리즘 문제인지 하드웨어 문제인지 진단해야 합니다.

### **3.2. Velocity Tracking Error (RMSE)**
*   **판단:** **"핵심 성능 지표 (Core Performance Metric)"**
*   **공식:** $\sqrt{\frac{1}{N}\sum(v_{cmd} - v_{est})^2}$
*   **유효성:**
    *   사용자의 의도대로 제어되는지를 판단하는 가장 직관적인 척도입니다.
*   **한계:**
    *   **State Estimation의 정확도**에 전적으로 의존합니다. 추정 알고리즘이 틀리면 지표도 틀립니다.
*   **결론:**
    *   평지 주행에서는 절대적인 기준이 되지만, 험지에서는 **Torque Smoothness**와 함께 봐야 합니다. (억지로 속도를 맞추려다 모터가 진동하는지 확인)

### **3.3. Torque Smoothness (Jitter)**
*   **판단:** **"하드웨어 생존 지표 (Hardware Survival Metric)"**
*   **공식:** $\frac{1}{N}\sum|\tau_t - \tau_{t-1}|$
*   **유효성:**
    *   **Sim-to-Real Gap**을 가장 적나라하게 보여줍니다. 시뮬레이션은 물리 엔진의 한계로 인해 실제보다 훨씬 부드럽게 움직입니다.
    *   이 수치가 높으면 기어 박스 파손, 모터 과열로 직결됩니다.
*   **결론:**
    *   성능(RMSE)이 좋아도 이 수치가 나쁘면 **배포 불가(Not Deployable)** 판정을 내려야 합니다.

### **3.4. Undesired Contacts (충돌 횟수)**
*   **판단:** **"안정성 지표 (Stability Metric)"**
*   **유효성:**
    *   넘어짐(Fall)이나 충돌을 카운트하여 모델의 기본 안정성을 평가합니다.
*   **한계:**
    *   **이진 분류(Binary)** 의 성격을 가집니다. "넘어졌다/안 넘어졌다"만 알 수 있고, "얼마나 불안하게 비틀거렸는지"는 알 수 없습니다.

---

## **4. 결론 : 계층적 평가 프로세스 (Hierarchical Evaluation)**

단일 지표 하나로 모델을 평가하려는 시도는 실패할 수밖에 없습니다. 다음과 같은 **우선순위 기반의 평가 프로세스**를 제안합니다.

1.  **Level 1: 생존성 (Survival)**
    *   질문: "로봇이 넘어지지 않고 완주했는가?"
    *   지표: **Undesired Contacts == 0**

2.  **Level 2: 안전성 (Safety)**
    *   질문: "모터가 비정상적으로 떨리지 않는가?"
    *   지표: **Torque Smoothness < Threshold** (하드웨어 보호 기준)

3.  **Level 3: 제어 성능 (Controllability)**
    *   질문: "명령한 속도대로 주행했는가?"
    *   지표: **Velocity RMSE < 0.1 m/s**

4.  **Level 4: 에너지 효율 (Efficiency)**
    *   질문: "(위 조건을 모두 만족할 때) 얼마나 효율적인가?"
    *   지표: **Filtered CoT (Speed > 0.2 m/s)**

**결론:**
현재 구축된 평가 시스템은 단순한 수치 기록을 넘어, **Smart Logging**과 **Robust Estimation**을 통해 위 4단계 평가를 수행할 수 있는 신뢰성 있는 데이터를 제공합니다. 이제 연구자는 "CoT가 왜 높지?"를 고민하기 전에, **"Level 1~3을 통과했는가?"** 를 먼저 확인해야 합니다.